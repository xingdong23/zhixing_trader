"""
Kçº¿æ•°æ®è¿ç§»è„šæœ¬
å°†å•ä¸€klinesè¡¨çš„æ•°æ®è¿ç§»åˆ°å¤šä¸ªæ—¶é—´å‘¨æœŸè¡¨
"""
import sys
import os
from datetime import datetime

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../.."))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from loguru import logger

from app.config import settings
from app.models import (
    Base,
    KLineDB,
    KLine1MinDB,
    KLine3MinDB,
    KLine5MinDB,
    KLine15MinDB,
    KLine30MinDB,
    KLine1HourDB,
    KLine4HourDB,
    KLineDailyDB,
    KLineWeeklyDB,
    KLineMonthlyDB,
    KLineTableManager,
)


# åˆ›å»ºæ•°æ®åº“è¿æ¥
engine = create_engine(
    settings.db_url,
    pool_pre_ping=True,
    echo=False  # è®¾ç½®ä¸ºTrueå¯ä»¥çœ‹åˆ°SQLè¯­å¥
)
SessionLocal = sessionmaker(bind=engine)


# æ—§periodå­—æ®µåˆ°æ–°æ—¶é—´å‘¨æœŸçš„æ˜ å°„
LEGACY_PERIOD_MAPPING = {
    "K_1M": "1m",
    "K_3M": "3m",
    "K_5M": "5m",
    "K_15M": "15m",
    "K_30M": "30m",
    "K_1H": "1h",
    "K_60M": "1h",
    "K_4H": "4h",
    "K_DAY": "1d",
    "K_WEEK": "1w",
    "K_MON": "1M",
    # å…¶ä»–å¯èƒ½çš„æ ¼å¼
    "1m": "1m",
    "3m": "3m",
    "5m": "5m",
    "15m": "15m",
    "30m": "30m",
    "1h": "1h",
    "60m": "1h",
    "4h": "4h",
    "1d": "1d",
    "1w": "1w",
    "1M": "1M",
}


def print_section(title: str):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)


def create_new_tables():
    """åˆ›å»ºæ–°çš„å¤šæ—¶é—´å‘¨æœŸè¡¨"""
    print_section("1. åˆ›å»ºæ–°çš„å¤šæ—¶é—´å‘¨æœŸè¡¨")
    
    try:
        # åˆ›å»ºæ‰€æœ‰æ–°è¡¨
        for model in KLineTableManager.ALL_MODELS:
            table_name = model.__tablename__
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å·²å­˜åœ¨
            with engine.connect() as conn:
                result = conn.execute(text(
                    f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'"
                ))
                exists = result.fetchone() is not None
            
            if exists:
                print(f"   âœ“ è¡¨ {table_name} å·²å­˜åœ¨")
            else:
                model.__table__.create(engine)
                print(f"   âœ… åˆ›å»ºè¡¨ {table_name}")
        
        print("\nâœ… æ‰€æœ‰è¡¨åˆ›å»ºå®Œæˆ")
        return True
    
    except Exception as e:
        logger.error(f"åˆ›å»ºè¡¨å¤±è´¥: {e}")
        print(f"\nâŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
        return False


def analyze_legacy_data():
    """åˆ†ææ—§è¡¨æ•°æ®"""
    print_section("2. åˆ†ææ—§è¡¨æ•°æ®")
    
    session = SessionLocal()
    
    try:
        # æ£€æŸ¥æ—§è¡¨æ˜¯å¦å­˜åœ¨
        with engine.connect() as conn:
            result = conn.execute(text(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='klines'"
            ))
            exists = result.fetchone() is not None
        
        if not exists:
            print("   âš ï¸  æ—§è¡¨ 'klines' ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®è¿ç§»")
            return {}
        
        # ç»Ÿè®¡å„ä¸ªæ—¶é—´å‘¨æœŸçš„æ•°æ®é‡
        total_count = session.query(KLineDB).count()
        print(f"\n   æ€»æ•°æ®é‡: {total_count:,} æ¡")
        
        if total_count == 0:
            print("   âš ï¸  æ—§è¡¨æ— æ•°æ®ï¼Œè·³è¿‡è¿ç§»")
            return {}
        
        # æŒ‰periodåˆ†ç»„ç»Ÿè®¡
        period_stats = {}
        
        result = session.execute(text(
            "SELECT period, COUNT(*) as count FROM klines GROUP BY period"
        ))
        
        print(f"\n   å„æ—¶é—´å‘¨æœŸæ•°æ®é‡:")
        for row in result:
            period, count = row
            normalized_period = LEGACY_PERIOD_MAPPING.get(period)
            
            if normalized_period:
                period_stats[period] = {
                    "count": count,
                    "normalized": normalized_period
                }
                print(f"      {period:12} â†’ {normalized_period:8} : {count:,} æ¡")
            else:
                print(f"      {period:12} â†’ âš ï¸  æœªçŸ¥     : {count:,} æ¡ (å°†è·³è¿‡)")
        
        return period_stats
    
    finally:
        session.close()


def migrate_data(batch_size=1000, dry_run=False):
    """è¿ç§»æ•°æ®"""
    print_section("3. è¿ç§»æ•°æ®")
    
    if dry_run:
        print("   ğŸ” DRY RUN æ¨¡å¼ - ä¸ä¼šå®é™…å†™å…¥æ•°æ®\n")
    
    session = SessionLocal()
    
    try:
        # è·å–æ‰€æœ‰æ—§æ•°æ®çš„periodç±»å‹
        periods = session.execute(text(
            "SELECT DISTINCT period FROM klines"
        )).fetchall()
        
        total_migrated = 0
        total_skipped = 0
        
        for (period,) in periods:
            normalized_period = LEGACY_PERIOD_MAPPING.get(period)
            
            if not normalized_period:
                print(f"   âš ï¸  è·³è¿‡æœªçŸ¥period: {period}")
                count = session.query(KLineDB).filter(KLineDB.period == period).count()
                total_skipped += count
                continue
            
            # è·å–ç›®æ ‡è¡¨æ¨¡å‹
            try:
                target_model = KLineTableManager.get_model_by_period(normalized_period)
                table_name = target_model.__tablename__
            except ValueError as e:
                print(f"   âŒ {e}")
                continue
            
            # ç»Ÿè®¡éœ€è¦è¿ç§»çš„æ•°æ®é‡
            total_records = session.query(KLineDB).filter(
                KLineDB.period == period
            ).count()
            
            print(f"\n   è¿ç§» {period} â†’ {table_name}")
            print(f"      æ€»æ•°: {total_records:,} æ¡")
            
            if dry_run:
                print(f"      âœ“ DRY RUN - è·³è¿‡å®é™…è¿ç§»")
                total_migrated += total_records
                continue
            
            # åˆ†æ‰¹è¿ç§»
            migrated_count = 0
            offset = 0
            
            while offset < total_records:
                # æ‰¹é‡è¯»å–æ—§æ•°æ®
                old_records = session.query(KLineDB).filter(
                    KLineDB.period == period
                ).offset(offset).limit(batch_size).all()
                
                if not old_records:
                    break
                
                # è½¬æ¢ä¸ºæ–°è®°å½•
                new_records = []
                for old in old_records:
                    try:
                        # è§£ætrade_timeï¼ˆå¦‚æœtime_keyæ˜¯æ—¥æœŸå­—ç¬¦ä¸²ï¼‰
                        trade_time = None
                        if old.time_key:
                            try:
                                trade_time = datetime.strptime(old.time_key, "%Y-%m-%d")
                            except ValueError:
                                try:
                                    trade_time = datetime.strptime(old.time_key, "%Y-%m-%d %H:%M:%S")
                                except ValueError:
                                    trade_time = datetime.utcnow()
                        else:
                            trade_time = datetime.utcnow()
                        
                        new_record = target_model(
                            code=old.code,
                            time_key=old.time_key,
                            trade_time=trade_time,
                            open_price=old.open_price,
                            close_price=old.close_price,
                            high_price=old.high_price,
                            low_price=old.low_price,
                            volume=old.volume,
                            turnover=old.turnover,
                            change_rate=old.change_rate,
                            amplitude=None,  # æ—§è¡¨æ²¡æœ‰è¿™ä¸ªå­—æ®µ
                            created_at=old.created_at or datetime.utcnow(),
                        )
                        new_records.append(new_record)
                    
                    except Exception as e:
                        logger.error(f"è½¬æ¢è®°å½•å¤±è´¥: {e}, è®°å½•ID: {old.id}")
                
                # æ‰¹é‡æ’å…¥æ–°è®°å½•
                if new_records:
                    session.bulk_save_objects(new_records)
                    session.commit()
                    migrated_count += len(new_records)
                
                offset += batch_size
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = min(100, (offset / total_records) * 100)
                print(f"      è¿›åº¦: {progress:5.1f}% ({migrated_count:,}/{total_records:,})", end="\r")
            
            print(f"      âœ… å®Œæˆ: {migrated_count:,} æ¡")
            total_migrated += migrated_count
        
        print(f"\nâœ… è¿ç§»å®Œæˆ")
        print(f"   æ€»è¿ç§»: {total_migrated:,} æ¡")
        if total_skipped > 0:
            print(f"   æ€»è·³è¿‡: {total_skipped:,} æ¡")
        
        return True
    
    except Exception as e:
        logger.error(f"è¿ç§»æ•°æ®å¤±è´¥: {e}")
        print(f"\nâŒ è¿ç§»å¤±è´¥: {e}")
        session.rollback()
        return False
    
    finally:
        session.close()


def verify_migration():
    """éªŒè¯è¿ç§»ç»“æœ"""
    print_section("4. éªŒè¯è¿ç§»ç»“æœ")
    
    session = SessionLocal()
    
    try:
        print("\n   æ–°è¡¨æ•°æ®ç»Ÿè®¡:")
        
        total_new_records = 0
        
        for model in KLineTableManager.ALL_MODELS:
            count = session.query(model).count()
            period = KLineTableManager.get_period_by_model(model)
            table_name = model.__tablename__
            
            print(f"      {table_name:20} ({period:4}) : {count:,} æ¡")
            total_new_records += count
        
        print(f"\n   æ–°è¡¨æ€»æ•°æ®é‡: {total_new_records:,} æ¡")
        
        # å¯¹æ¯”æ—§è¡¨æ•°æ®é‡
        old_count = session.query(KLineDB).count()
        print(f"   æ—§è¡¨æ€»æ•°æ®é‡: {old_count:,} æ¡")
        
        if total_new_records == old_count:
            print(f"\n   âœ… æ•°æ®é‡ä¸€è‡´ï¼Œè¿ç§»æˆåŠŸï¼")
        else:
            diff = abs(total_new_records - old_count)
            print(f"\n   âš ï¸  æ•°æ®é‡å·®å¼‚: {diff:,} æ¡")
        
        return True
    
    finally:
        session.close()


def backup_old_table():
    """å¤‡ä»½æ—§è¡¨"""
    print_section("å¤‡ä»½æ—§è¡¨")
    
    try:
        with engine.connect() as conn:
            # æ£€æŸ¥å¤‡ä»½è¡¨æ˜¯å¦å·²å­˜åœ¨
            result = conn.execute(text(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='klines_backup'"
            ))
            exists = result.fetchone() is not None
            
            if exists:
                print("   âš ï¸  å¤‡ä»½è¡¨ 'klines_backup' å·²å­˜åœ¨")
                response = input("   æ˜¯å¦è¦†ç›–ï¼Ÿ(y/N): ").strip().lower()
                if response != 'y':
                    print("   è·³è¿‡å¤‡ä»½")
                    return True
                
                conn.execute(text("DROP TABLE klines_backup"))
                conn.commit()
            
            # åˆ›å»ºå¤‡ä»½
            conn.execute(text(
                "CREATE TABLE klines_backup AS SELECT * FROM klines"
            ))
            conn.commit()
            
            # éªŒè¯å¤‡ä»½
            result = conn.execute(text("SELECT COUNT(*) FROM klines_backup"))
            count = result.fetchone()[0]
            
            print(f"   âœ… å¤‡ä»½å®Œæˆ: {count:,} æ¡è®°å½•")
            return True
    
    except Exception as e:
        logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
        print(f"   âŒ å¤‡ä»½å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ”„"*40)
    print("  Kçº¿æ•°æ®è¿ç§»å·¥å…·")
    print("  ä»å•è¡¨ klines è¿ç§»åˆ°å¤šæ—¶é—´å‘¨æœŸè¡¨")
    print("ğŸ”„"*40)
    
    # æ˜¾ç¤ºé…ç½®
    print(f"\næ•°æ®åº“: {settings.db_url}")
    
    # è¯¢é—®æ˜¯å¦æ‰§è¡Œ
    print("\nâš ï¸  æ­¤æ“ä½œå°†ï¼š")
    print("   1. åˆ›å»ºæ–°çš„å¤šæ—¶é—´å‘¨æœŸè¡¨")
    print("   2. å°†æ—§è¡¨æ•°æ®è¿ç§»åˆ°æ–°è¡¨")
    print("   3. ä¸ä¼šåˆ é™¤æ—§è¡¨ï¼ˆä¿ç•™ç”¨äºå›æ»šï¼‰")
    
    response = input("\næ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
    
    if response != 'y':
        print("\nâŒ æ“ä½œå·²å–æ¶ˆ")
        return
    
    # è¯¢é—®æ˜¯å¦DRY RUN
    dry_run_response = input("æ˜¯å¦å…ˆè¿›è¡ŒDRY RUNæµ‹è¯•ï¼Ÿ(Y/n): ").strip().lower()
    dry_run = dry_run_response != 'n'
    
    # æ‰§è¡Œè¿ç§»æ­¥éª¤
    print("\n" + "â–¶ï¸ "*40)
    print("  å¼€å§‹è¿ç§»...")
    print("â–¶ï¸ "*40)
    
    # 1. åˆ›å»ºæ–°è¡¨
    if not create_new_tables():
        print("\nâŒ è¿ç§»ç»ˆæ­¢")
        return
    
    # 2. åˆ†ææ—§æ•°æ®
    period_stats = analyze_legacy_data()
    
    if not period_stats:
        print("\nâœ… æ— éœ€è¿ç§»æ•°æ®")
        return
    
    # 3. è¿ç§»æ•°æ®
    if not migrate_data(batch_size=1000, dry_run=dry_run):
        print("\nâŒ è¿ç§»ç»ˆæ­¢")
        return
    
    if dry_run:
        print("\n" + "="*80)
        print("  DRY RUN å®Œæˆ")
        print("="*80)
        print("\nå¦‚æœç»“æœæ­£ç¡®ï¼Œè¯·é‡æ–°è¿è¡Œå¹¶é€‰æ‹©å®é™…è¿ç§»")
        return
    
    # 4. éªŒè¯è¿ç§»
    verify_migration()
    
    # 5. è¯¢é—®æ˜¯å¦å¤‡ä»½æ—§è¡¨
    print("\n" + "="*80)
    backup_response = input("\næ˜¯å¦å¤‡ä»½æ—§è¡¨åˆ° klines_backupï¼Ÿ(Y/n): ").strip().lower()
    
    if backup_response != 'n':
        backup_old_table()
    
    # å®Œæˆ
    print("\n" + "="*80)
    print("  âœ… è¿ç§»å®Œæˆï¼")
    print("="*80)
    
    print("""
ğŸ“Œ åç»­æ“ä½œå»ºè®®:

1. éªŒè¯æ–°è¡¨æ•°æ®
   â€¢ è¿è¡Œæµ‹è¯•æŸ¥è¯¢ï¼Œç¡®ä¿æ•°æ®æ­£ç¡®
   â€¢ æ£€æŸ¥å„ä¸ªæ—¶é—´å‘¨æœŸçš„æ•°æ®

2. æ›´æ–°åº”ç”¨ä»£ç 
   â€¢ æ›´æ–°æ•°æ®è®¿é—®å±‚ä½¿ç”¨æ–°è¡¨
   â€¢ æµ‹è¯•åº”ç”¨åŠŸèƒ½

3. ä¿ç•™æ—§è¡¨ä¸€æ®µæ—¶é—´
   â€¢ å»ºè®®ä¿ç•™1-2å‘¨ç”¨äºå›æ»š
   â€¢ ç¡®è®¤æ— é—®é¢˜åå†åˆ é™¤

4. ä¼˜åŒ–æ•°æ®åº“
   â€¢ VACUUM å‘½ä»¤ä¼˜åŒ–æ•°æ®åº“æ–‡ä»¶å¤§å°
   â€¢ æ›´æ–°ç»Ÿè®¡ä¿¡æ¯

5. å¦‚éœ€å›æ»š
   â€¢ ä» klines_backup æ¢å¤æ•°æ®
   â€¢ æˆ–ä½¿ç”¨æ•°æ®åº“å¤‡ä»½

ğŸ‰ æ•°æ®è¿ç§»æˆåŠŸï¼
    """)


if __name__ == "__main__":
    main()

