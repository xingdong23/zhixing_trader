"""
å®Œæ•´çš„è‚¡ç¥¨æ± åˆå§‹åŒ–è„šæœ¬ï¼ˆåŒ…å«åˆ†ç±»ï¼‰
è‡ªåŠ¨è·å–è‚¡ç¥¨ä¿¡æ¯ã€åˆ›å»ºåˆ†ç±»æ ‘ã€å»ºç«‹å…³è”å…³ç³»

åŠŸèƒ½ï¼š
1. ä»ç§å­æ–‡ä»¶/Wikipediaè·å–è‚¡ç¥¨ä»£ç 
2. ä½¿ç”¨yfinanceè·å–è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬Sectorã€Industryï¼‰
3. è‡ªåŠ¨åˆ›å»ºåˆ†ç±»å±‚çº§ï¼ˆSector â†’ Industryï¼‰
4. å»ºç«‹è‚¡ç¥¨ä¸åˆ†ç±»çš„å…³è”å…³ç³»
5. å¡«å…… stocksã€categoriesã€category_stock_relations ä¸‰ä¸ªè¡¨
"""
import sys
from pathlib import Path
import time
from collections import defaultdict
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import yfinance as yf
from loguru import logger
from sqlalchemy import create_engine, text
from app.config import settings


def get_stocks_from_seed_file():
    """ä»ç§å­æ–‡ä»¶è·å–è‚¡ç¥¨ä»£ç """
    
    seed_file = project_root / 'data' / 'us_stock_symbols.txt'
    
    if not seed_file.exists():
        logger.warning(f"ç§å­æ–‡ä»¶ä¸å­˜åœ¨: {seed_file}")
        return []
    
    all_symbols = set()
    
    logger.info(f"ä»ç§å­æ–‡ä»¶è¯»å–: {seed_file}")
    
    with open(seed_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            symbols = [s.strip().upper() for s in line.split(',') if s.strip()]
            all_symbols.update(symbols)
    
    logger.info(f"âœ… ä»ç§å­æ–‡ä»¶è·å–: {len(all_symbols)} åªè‚¡ç¥¨")
    return list(all_symbols)


def get_stocks_from_wikipedia():
    """ä»Wikipediaè·å–è‚¡ç¥¨ä»£ç ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    
    all_symbols = set()
    
    import requests
    from io import StringIO
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # S&P 600ï¼ˆå°ç›˜è‚¡ï¼Œçº¦600åªï¼‰
    logger.info("æ­£åœ¨è·å– S&P 600...")
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_600_companies"
        response = requests.get(url, headers=headers)
        tables = pd.read_html(StringIO(response.text))
        df = tables[0]
        symbols = df['Symbol'].dropna().tolist()
        all_symbols.update(symbols)
        logger.info(f"âœ… S&P 600: {len(symbols)} åª")
    except Exception as e:
        logger.warning(f"âš ï¸ S&P 600è·å–å¤±è´¥: {e}")
    
    # NASDAQ 100ï¼ˆç§‘æŠ€è‚¡ï¼‰
    logger.info("æ­£åœ¨è·å– NASDAQ 100...")
    try:
        url = "https://en.wikipedia.org/wiki/Nasdaq-100"
        response = requests.get(url, headers=headers)
        tables = pd.read_html(StringIO(response.text))
        for table in tables:
            if 'Ticker' in table.columns:
                symbols = table['Ticker'].dropna().tolist()
                if len(symbols) > 50:
                    all_symbols.update(symbols)
                    logger.info(f"âœ… NASDAQ 100: {len(symbols)} åª")
                    break
    except Exception as e:
        logger.warning(f"âš ï¸ NASDAQ 100è·å–å¤±è´¥: {e}")
    
    logger.info(f"æ€»è®¡è·å–: {len(all_symbols)} åªè‚¡ç¥¨ï¼ˆå»é‡åï¼‰")
    return list(all_symbols)


def fetch_stock_details(symbols, batch_size=50):
    """
    è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬Sectorå’ŒIndustryï¼‰
    
    Returns:
        list: åŒ…å«å®Œæ•´ä¿¡æ¯çš„è‚¡ç¥¨åˆ—è¡¨
    """
    stocks_with_details = []
    total = len(symbols)
    
    logger.info(f"å¼€å§‹è·å– {total} åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯...")
    logger.info(f"ç­›é€‰æ¡ä»¶: å¸‚å€¼ $500M-$10B, ä»·æ ¼ $5-$150")
    
    for i, symbol in enumerate(symbols, 1):
        try:
            clean_symbol = symbol.strip().upper()
            if not clean_symbol or '.' in clean_symbol:
                continue
            
            # è·å–è‚¡ç¥¨ä¿¡æ¯
            ticker = yf.Ticker(clean_symbol)
            info = ticker.info
            
            # æå–å…³é”®ä¿¡æ¯
            market_cap = info.get('marketCap', 0) or info.get('enterpriseValue', 0)
            current_price = info.get('currentPrice', 0) or info.get('regularMarketPrice', 0)
            sector = info.get('sector', 'Unknown') or 'Unknown'
            industry = info.get('industry', 'Unknown') or 'Unknown'
            
            # ç­›é€‰æ¡ä»¶
            if market_cap > 0 and current_price > 0:
                # å¸‚å€¼ï¼š5äº¿-100äº¿ç¾å…ƒ
                if 500_000_000 <= market_cap <= 10_000_000_000:
                    # ä»·æ ¼ï¼š$5-$150
                    if 5 <= current_price <= 150:
                        stock_data = {
                            'code': clean_symbol,
                            'name': info.get('shortName', clean_symbol)[:200],
                            'market': 'US',
                            'sector': sector[:50],
                            'industry': industry[:100],
                            'market_cap': round(market_cap / 1_000_000, 2),  # ç™¾ä¸‡ç¾å…ƒ
                            'current_price': round(current_price, 2),
                            # é¢å¤–ä¿¡æ¯ç”¨äºåˆ†ç±»
                            'exchange': info.get('exchange', 'Unknown'),
                            'country': info.get('country', 'US'),
                        }
                        stocks_with_details.append(stock_data)
            
            # è¿›åº¦æ˜¾ç¤º
            if i % batch_size == 0:
                logger.info(f"è¿›åº¦: {i}/{total} ({i*100//total}%), å·²ç­›é€‰: {len(stocks_with_details)} åª")
            
            # é™æµ
            if i % 10 == 0:
                time.sleep(0.5)
        
        except Exception as e:
            logger.debug(f"è·³è¿‡ {symbol}: {str(e)[:50]}")
            continue
    
    logger.info(f"âœ… è·å–å®Œæˆ: {len(stocks_with_details)}/{total} åªè‚¡ç¥¨ç¬¦åˆæ¡ä»¶")
    return stocks_with_details


def normalize_category_id(name: str) -> str:
    """
    å°†åˆ†ç±»åç§°è½¬æ¢ä¸ºcategory_id
    ä¾‹å¦‚: "Healthcare" -> "healthcare", "Oil & Gas" -> "oil_gas"
    """
    return name.lower().replace(' ', '_').replace('&', 'and').replace('-', '_')


def build_category_tree(stocks):
    """
    ä»è‚¡ç¥¨ä¿¡æ¯æ„å»ºåˆ†ç±»æ ‘
    
    ç»“æ„:
    - Sector (Level 0)
      - Industry (Level 1)
    
    Returns:
        tuple: (categories_list, relations_list)
    """
    logger.info("æ„å»ºåˆ†ç±»æ ‘...")
    
    # æ”¶é›†æ‰€æœ‰çš„ Sector å’Œ Industry
    sector_industries = defaultdict(set)
    
    for stock in stocks:
        sector = stock['sector']
        industry = stock['industry']
        if sector and sector != 'Unknown':
            sector_industries[sector].add(industry if industry != 'Unknown' else 'Other')
    
    categories = []
    relations = []
    
    # åˆ›å»º Sector åˆ†ç±»ï¼ˆLevel 0ï¼‰
    for sector_name in sorted(sector_industries.keys()):
        sector_id = normalize_category_id(sector_name)
        
        categories.append({
            'category_id': sector_id,
            'name': sector_name,
            'parent_id': None,
            'path': f'/{sector_id}',
            'level': 0,
            'sort_order': 0,
            'icon': get_sector_icon(sector_name),
            'color': get_sector_color(sector_name),
            'description': f'{sector_name} sector stocks',
            'is_active': True,
            'is_custom': False,
        })
        
        # åˆ›å»º Industry åˆ†ç±»ï¼ˆLevel 1ï¼‰
        industries = sorted(sector_industries[sector_name])
        for idx, industry_name in enumerate(industries):
            industry_id = f"{sector_id}_{normalize_category_id(industry_name)}"
            
            categories.append({
                'category_id': industry_id,
                'name': industry_name,
                'parent_id': sector_id,
                'path': f'/{sector_id}/{industry_id}',
                'level': 1,
                'sort_order': idx,
                'icon': 'ğŸ“Š',
                'color': get_sector_color(sector_name),
                'description': f'{industry_name} in {sector_name}',
                'is_active': True,
                'is_custom': False,
            })
    
    logger.info(f"âœ… åˆ›å»ºäº† {len(categories)} ä¸ªåˆ†ç±»")
    logger.info(f"   - Sectors: {len(sector_industries)}")
    logger.info(f"   - Industries: {len(categories) - len(sector_industries)}")
    
    # å»ºç«‹è‚¡ç¥¨ä¸åˆ†ç±»çš„å…³è”å…³ç³»
    for stock in stocks:
        sector = stock['sector']
        industry = stock['industry']
        code = stock['code']
        
        if sector and sector != 'Unknown':
            sector_id = normalize_category_id(sector)
            
            # å…³è”åˆ° Sectorï¼ˆæ¬¡è¦åˆ†ç±»ï¼‰
            relations.append({
                'category_id': sector_id,
                'stock_code': code,
                'weight': 1.0,
                'is_primary': False,
                'notes': f'Sector: {sector}',
            })
            
            # å…³è”åˆ° Industryï¼ˆä¸»è¦åˆ†ç±»ï¼‰
            if industry and industry != 'Unknown':
                industry_name = industry
            else:
                industry_name = 'Other'
            
            industry_id = f"{sector_id}_{normalize_category_id(industry_name)}"
            relations.append({
                'category_id': industry_id,
                'stock_code': code,
                'weight': 1.0,
                'is_primary': True,
                'notes': f'Industry: {industry_name}',
            })
    
    logger.info(f"âœ… åˆ›å»ºäº† {len(relations)} æ¡å…³è”å…³ç³»")
    
    return categories, relations


def get_sector_icon(sector: str) -> str:
    """ä¸ºä¸åŒæ¿å—åˆ†é…å›¾æ ‡"""
    icons = {
        'Technology': 'ğŸ’»',
        'Healthcare': 'ğŸ¥',
        'Financial Services': 'ğŸ’°',
        'Consumer Cyclical': 'ğŸ›’',
        'Consumer Defensive': 'ğŸ¥«',
        'Industrials': 'ğŸ­',
        'Energy': 'âš¡',
        'Utilities': 'ğŸ’¡',
        'Real Estate': 'ğŸ ',
        'Basic Materials': 'â›ï¸',
        'Communication Services': 'ğŸ“¡',
    }
    return icons.get(sector, 'ğŸ“Š')


def get_sector_color(sector: str) -> str:
    """ä¸ºä¸åŒæ¿å—åˆ†é…é¢œè‰²"""
    colors = {
        'Technology': '#4299e1',       # è“è‰²
        'Healthcare': '#48bb78',       # ç»¿è‰²
        'Financial Services': '#ed8936', # æ©™è‰²
        'Consumer Cyclical': '#9f7aea', # ç´«è‰²
        'Consumer Defensive': '#38b2ac', # é’è‰²
        'Industrials': '#667eea',      # é›è“
        'Energy': '#f56565',           # çº¢è‰²
        'Utilities': '#ecc94b',        # é»„è‰²
        'Real Estate': '#ed64a6',      # ç²‰è‰²
        'Basic Materials': '#a0aec0',  # ç°è‰²
        'Communication Services': '#4299e1', # è“è‰²
    }
    return colors.get(sector, '#718096')


def save_to_database(stocks, categories, relations):
    """ä¿å­˜æ‰€æœ‰æ•°æ®åˆ°æ•°æ®åº“"""
    
    if not stocks:
        logger.warning("æ²¡æœ‰è‚¡ç¥¨éœ€è¦ä¿å­˜")
        return
    
    try:
        engine = create_engine(settings.database_url)
        
        with engine.connect() as conn:
            logger.info("\nã€ä¿å­˜åˆ°æ•°æ®åº“ã€‘")
            
            # 1. ä¿å­˜è‚¡ç¥¨ä¿¡æ¯
            logger.info(f"1ï¸âƒ£ ä¿å­˜ {len(stocks)} åªè‚¡ç¥¨...")
            
            # å‡†å¤‡stocksæ•°æ®ï¼ˆåªä¿ç•™æ•°æ®åº“å­—æ®µï¼‰
            stocks_for_db = []
            for s in stocks:
                stocks_for_db.append({
                    'code': s['code'],
                    'name': s['name'],
                    'market': s['market'],
                    'market_cap': 'small',  # ç®€åŒ–ï¼Œéƒ½æ˜¯å°ç›˜è‚¡
                    'lot_size': 1,
                    'sec_type': 'STOCK',
                    'is_active': True,
                })
            
            df_stocks = pd.DataFrame(stocks_for_db)
            df_stocks.to_sql(
                'stocks',
                engine,
                if_exists='append',
                index=False,
                method='multi',
                chunksize=100
            )
            logger.info(f"   âœ… è‚¡ç¥¨ä¿å­˜å®Œæˆ")
            
            # 2. ä¿å­˜åˆ†ç±»
            logger.info(f"2ï¸âƒ£ ä¿å­˜ {len(categories)} ä¸ªåˆ†ç±»...")
            df_categories = pd.DataFrame(categories)
            
            # æ·»åŠ æ—¶é—´æˆ³
            now = datetime.utcnow()
            df_categories['created_at'] = now
            df_categories['updated_at'] = now
            df_categories['stock_count'] = 0
            df_categories['total_stock_count'] = 0
            
            df_categories.to_sql(
                'categories',
                engine,
                if_exists='append',
                index=False,
                method='multi',
                chunksize=100
            )
            logger.info(f"   âœ… åˆ†ç±»ä¿å­˜å®Œæˆ")
            
            # 3. ä¿å­˜å…³è”å…³ç³»
            logger.info(f"3ï¸âƒ£ ä¿å­˜ {len(relations)} æ¡å…³è”å…³ç³»...")
            df_relations = pd.DataFrame(relations)
            
            # æ·»åŠ æ—¶é—´æˆ³
            df_relations['created_at'] = now
            df_relations['updated_at'] = now
            
            df_relations.to_sql(
                'category_stock_relations',
                engine,
                if_exists='append',
                index=False,
                method='multi',
                chunksize=200
            )
            logger.info(f"   âœ… å…³è”å…³ç³»ä¿å­˜å®Œæˆ")
            
            # 4. æ›´æ–°åˆ†ç±»çš„è‚¡ç¥¨æ•°é‡ç»Ÿè®¡
            logger.info(f"4ï¸âƒ£ æ›´æ–°åˆ†ç±»ç»Ÿè®¡...")
            conn.execute(text("""
                UPDATE categories c
                SET stock_count = (
                    SELECT COUNT(DISTINCT stock_code)
                    FROM category_stock_relations r
                    WHERE r.category_id = c.category_id
                )
            """))
            conn.commit()
            logger.info(f"   âœ… ç»Ÿè®¡æ›´æ–°å®Œæˆ")
        
        logger.info(f"âœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
    
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


def save_to_json(stocks, categories, relations):
    """ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼ˆå¤‡ä»½ï¼‰"""
    
    import json
    from pathlib import Path
    
    try:
        data_dir = project_root / 'data'
        data_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜è‚¡ç¥¨
        with open(data_dir / 'us_stocks.json', 'w', encoding='utf-8') as f:
            json.dump(stocks, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜åˆ†ç±»
        with open(data_dir / 'us_categories.json', 'w', encoding='utf-8') as f:
            json.dump(categories, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜å…³è”å…³ç³»
        with open(data_dir / 'us_category_relations.json', 'w', encoding='utf-8') as f:
            json.dump(relations, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜åˆ° {data_dir}")
    
    except Exception as e:
        logger.error(f"ä¿å­˜JSONå¤±è´¥: {e}")


def print_statistics(stocks, categories, relations):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    
    from collections import Counter
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æ•°æ®ç»Ÿè®¡æŠ¥å‘Š")
    logger.info("=" * 60)
    
    # è‚¡ç¥¨ç»Ÿè®¡
    logger.info(f"\nã€è‚¡ç¥¨ã€‘")
    logger.info(f"  æ€»æ•°: {len(stocks)} åª")
    
    sectors = Counter(s['sector'] for s in stocks)
    logger.info(f"\nã€æ¿å—åˆ†å¸ƒã€‘Top 10:")
    for sector, count in sectors.most_common(10):
        logger.info(f"  {sector:30s}: {count:3d} åª")
    
    # åˆ†ç±»ç»Ÿè®¡
    logger.info(f"\nã€åˆ†ç±»ã€‘")
    logger.info(f"  æ€»æ•°: {len(categories)} ä¸ª")
    level_0 = sum(1 for c in categories if c['level'] == 0)
    level_1 = sum(1 for c in categories if c['level'] == 1)
    logger.info(f"  - Sectors (Level 0): {level_0}")
    logger.info(f"  - Industries (Level 1): {level_1}")
    
    # å…³è”å…³ç³»ç»Ÿè®¡
    logger.info(f"\nã€å…³è”å…³ç³»ã€‘")
    logger.info(f"  æ€»æ•°: {len(relations)} æ¡")
    primary = sum(1 for r in relations if r['is_primary'])
    secondary = len(relations) - primary
    logger.info(f"  - ä¸»è¦åˆ†ç±»: {primary}")
    logger.info(f"  - æ¬¡è¦åˆ†ç±»: {secondary}")
    
    # å¸‚å€¼ç»Ÿè®¡
    market_caps = [s['market_cap'] for s in stocks]
    logger.info(f"\nã€å¸‚å€¼èŒƒå›´ã€‘")
    logger.info(f"  æœ€å°: ${min(market_caps):.1f}M")
    logger.info(f"  æœ€å¤§: ${max(market_caps):.1f}M")
    logger.info(f"  å¹³å‡: ${sum(market_caps)/len(market_caps):.1f}M")
    logger.info(f"  ä¸­ä½æ•°: ${sorted(market_caps)[len(market_caps)//2]:.1f}M")
    
    # éšæœºæ ·æœ¬
    import random
    samples = random.sample(stocks, min(5, len(stocks)))
    logger.info(f"\nã€éšæœºæ ·æœ¬ã€‘")
    for s in samples:
        logger.info(f"  {s['code']:6s} | {s['name']:30s} | {s['sector']:20s} | ${s['market_cap']:.0f}M")
    
    logger.info("=" * 60 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    
    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹æ„å»ºç¾è‚¡è‚¡ç¥¨æ± ï¼ˆå«åˆ†ç±»ï¼‰")
    logger.info("=" * 60)
    
    start_time = time.time()
    
    try:
        # æ­¥éª¤1: è·å–è‚¡ç¥¨ä»£ç 
        logger.info("\nã€æ­¥éª¤1ã€‘è·å–è‚¡ç¥¨ä»£ç ...")
        symbols = get_stocks_from_seed_file()
        
        if not symbols:
            logger.info("ç§å­æ–‡ä»¶ä¸ºç©ºï¼Œå°è¯•ä»Wikipediaè·å–...")
            symbols = get_stocks_from_wikipedia()
        
        if not symbols:
            logger.error("âŒ æœªèƒ½è·å–ä»»ä½•è‚¡ç¥¨ä»£ç ")
            logger.info("ğŸ’¡ æç¤ºï¼šè¯·ç¼–è¾‘ data/us_stock_symbols.txt æ·»åŠ è‚¡ç¥¨ä»£ç ")
            return
        
        # æ­¥éª¤2: è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬Sectorå’ŒIndustryï¼‰
        logger.info("\nã€æ­¥éª¤2ã€‘è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆå«Sector/Industryï¼‰...")
        stocks = fetch_stock_details(symbols)
        
        if not stocks:
            logger.error("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return
        
        # æ­¥éª¤3: æ„å»ºåˆ†ç±»æ ‘
        logger.info("\nã€æ­¥éª¤3ã€‘æ„å»ºåˆ†ç±»æ ‘...")
        categories, relations = build_category_tree(stocks)
        
        # æ­¥éª¤4: ä¿å­˜åˆ°æ•°æ®åº“
        logger.info("\nã€æ­¥éª¤4ã€‘ä¿å­˜åˆ°æ•°æ®åº“...")
        save_to_database(stocks, categories, relations)
        
        # æ­¥éª¤5: ä¿å­˜åˆ°JSONï¼ˆå¤‡ä»½ï¼‰
        logger.info("\nã€æ­¥éª¤5ã€‘ä¿å­˜åˆ°JSONæ–‡ä»¶...")
        save_to_json(stocks, categories, relations)
        
        # æ­¥éª¤6: æ‰“å°ç»Ÿè®¡
        logger.info("\nã€æ­¥éª¤6ã€‘ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        print_statistics(stocks, categories, relations)
        
        # å®Œæˆ
        elapsed = time.time() - start_time
        logger.info("=" * 60)
        logger.info(f"âœ… è‚¡ç¥¨æ± æ„å»ºå®Œæˆï¼")
        logger.info(f"   è‚¡ç¥¨æ•°: {len(stocks)} åª")
        logger.info(f"   åˆ†ç±»æ•°: {len(categories)} ä¸ª")
        logger.info(f"   å…³è”æ•°: {len(relations)} æ¡")
        logger.info(f"   è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
        logger.info("=" * 60)
    
    except Exception as e:
        logger.error(f"âŒ æ„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

