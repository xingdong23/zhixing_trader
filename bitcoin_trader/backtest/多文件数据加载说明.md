# 多文件数据加载说明

回测系统支持多种数据源格式，可以自动加载、合并和排序多个历史数据文件。

---

## 支持的数据源格式

### 1. 单个文件

```json
{
  "data": {
    "source": "data/ETH-USDT-1m-2025.10.23.csv"
  }
}
```

**说明**: 加载单个CSV文件

---

### 2. 多个文件（列表）

```json
{
  "data": {
    "source": [
      "data/ETH-USDT-1m-2025.10.01.csv",
      "data/ETH-USDT-1m-2025.10.02.csv",
      "data/ETH-USDT-1m-2025.10.03.csv"
    ]
  }
}
```

**说明**: 
- 加载多个指定的CSV文件
- 自动按时间排序合并
- 自动去除重复数据

---

### 3. 通配符匹配

```json
{
  "data": {
    "source": "data/ETH-USDT-*.csv"
  }
}
```

**说明**: 
- 使用通配符 `*` 匹配多个文件
- 自动加载所有匹配的文件
- 按文件名排序后加载

**示例**:
- `data/ETH-USDT-*.csv` - 匹配所有ETH-USDT的CSV文件
- `data/ETH-USDT-1m-2025.10.*.csv` - 匹配2025年10月的所有数据
- `data/*-USDT-*.csv` - 匹配所有USDT交易对的数据

---

### 4. 目录加载

```json
{
  "data": {
    "source": "data/"
  }
}
```

**说明**: 
- 加载目录下所有CSV文件
- 按文件名排序
- 自动合并和去重

---

## 数据处理流程

### 1. 文件发现
```
配置文件 → 解析路径 → 查找匹配文件 → 排序文件列表
```

### 2. 数据加载
```
遍历文件 → 读取CSV → 合并DataFrame → 按时间排序 → 去重
```

### 3. 数据验证
```
检查时间列 → 验证数据完整性 → 输出统计信息
```

---

## 使用示例

### 示例1: 加载单日数据

```json
{
  "backtest_name": "单日回测",
  "data": {
    "source": "data/ETH-USDT-1m-2025.10.23.csv",
    "timeframe": "5m",
    "resample_from": "1m"
  }
}
```

**运行**:
```bash
python backtest/run_backtest.py --config backtest/configs/single_day.json
```

**输出**:
```
找到 1 个数据文件
  加载: ETH-USDT-1m-2025.10.23.csv
✓ 加载完成: 1440 条数据
```

---

### 示例2: 加载一周数据

```json
{
  "backtest_name": "一周回测",
  "data": {
    "source": [
      "data/ETH-USDT-1m-2025.10.21.csv",
      "data/ETH-USDT-1m-2025.10.22.csv",
      "data/ETH-USDT-1m-2025.10.23.csv",
      "data/ETH-USDT-1m-2025.10.24.csv",
      "data/ETH-USDT-1m-2025.10.25.csv"
    ],
    "timeframe": "5m",
    "resample_from": "1m"
  }
}
```

**输出**:
```
找到 5 个数据文件
  加载: ETH-USDT-1m-2025.10.21.csv
  加载: ETH-USDT-1m-2025.10.22.csv
  加载: ETH-USDT-1m-2025.10.23.csv
  加载: ETH-USDT-1m-2025.10.24.csv
  加载: ETH-USDT-1m-2025.10.25.csv
合并多个文件...
✓ 已按时间排序
✓ 去除 0 条重复数据
✓ 加载完成: 7200 条数据
```

---

### 示例3: 使用通配符加载整月数据

```json
{
  "backtest_name": "整月回测",
  "data": {
    "source": "data/ETH-USDT-1m-2025.10.*.csv",
    "timeframe": "5m",
    "resample_from": "1m"
  }
}
```

**文件结构**:
```
data/
├── ETH-USDT-1m-2025.10.01.csv
├── ETH-USDT-1m-2025.10.02.csv
├── ETH-USDT-1m-2025.10.03.csv
...
└── ETH-USDT-1m-2025.10.31.csv
```

**输出**:
```
找到 31 个数据文件
  加载: ETH-USDT-1m-2025.10.01.csv
  加载: ETH-USDT-1m-2025.10.02.csv
  ...
  加载: ETH-USDT-1m-2025.10.31.csv
合并多个文件...
✓ 已按时间排序
✓ 去除 15 条重复数据
✓ 加载完成: 44625 条数据
```

---

### 示例4: 加载目录下所有数据

```json
{
  "backtest_name": "全量回测",
  "data": {
    "source": "data/",
    "timeframe": "5m",
    "resample_from": "1m"
  }
}
```

**说明**: 加载 `data/` 目录下所有CSV文件

---

## 数据文件命名规范

### 推荐格式

```
{交易对}-{时间框架}-{日期}.csv

示例:
ETH-USDT-1m-2025.10.23.csv
BTC-USDT-1m-2025.10.23.csv
SOL-USDT-5m-2025.10.23.csv
```

### 命名优势

1. **自动排序**: 按日期自然排序
2. **易于识别**: 一眼看出交易对和日期
3. **通配符友好**: 便于使用 `*` 匹配

---

## 数据合并规则

### 1. 时间排序

所有数据按 `open_time` 字段排序：
```python
df.sort_values('open_time').reset_index(drop=True)
```

### 2. 去重规则

如果多个文件包含相同时间戳的数据：
- 保留第一个出现的数据
- 删除后续重复的数据
- 记录去重数量

```python
df.drop_duplicates(subset=['open_time'], keep='first')
```

### 3. 数据验证

- 检查必需字段: `open_time`, `open`, `high`, `low`, `close`, `vol`
- 验证时间连续性
- 检测数据缺失

---

## 性能优化

### 大数据量处理

**问题**: 加载几个月的1分钟数据（数百万条）可能很慢

**优化方案**:

1. **分批加载**
   ```json
   {
     "data": {
       "source": "data/ETH-USDT-1m-2025.10.*.csv"
     }
   }
   ```

2. **使用5分钟数据**
   ```json
   {
     "data": {
       "source": "data/ETH-USDT-5m-2025.10.*.csv",
       "timeframe": "5m",
       "resample_from": "5m"
     }
   }
   ```

3. **预处理数据**
   ```bash
   # 合并多个文件为一个
   python scripts/merge_data.py --input "data/ETH-*.csv" --output "data/ETH-merged.csv"
   ```

---

## 常见问题

### Q1: 文件顺序会影响结果吗？

**A**: 不会。系统会自动按时间排序，无论文件顺序如何。

---

### Q2: 如果文件有重叠时间怎么办？

**A**: 系统会自动去重，保留第一个文件的数据。

---

### Q3: 支持不同交易对的数据吗？

**A**: 不支持。一次回测只能使用同一个交易对的数据。

---

### Q4: 数据文件必须按日期分割吗？

**A**: 不必须。可以是任何分割方式，系统会自动合并。

---

### Q5: 如何验证数据加载正确？

**A**: 查看日志输出：
```
找到 X 个数据文件
  加载: file1.csv
  加载: file2.csv
合并多个文件...
✓ 已按时间排序
✓ 去除 N 条重复数据
✓ 加载完成: M 条数据
```

---

## 最佳实践

### 1. 数据组织

```
data/
├── ETH-USDT/
│   ├── 2025-10-01.csv
│   ├── 2025-10-02.csv
│   └── ...
├── BTC-USDT/
│   ├── 2025-10-01.csv
│   └── ...
└── SOL-USDT/
    └── ...
```

**配置**:
```json
{
  "data": {
    "source": "data/ETH-USDT/*.csv"
  }
}
```

### 2. 配置管理

为不同时间段创建不同配置：

```
configs/
├── backtest_single_day.json      # 单日测试
├── backtest_week.json            # 一周测试
├── backtest_month.json           # 整月测试
└── backtest_quarter.json         # 季度测试
```

### 3. 数据备份

```bash
# 定期备份原始数据
tar -czf data_backup_$(date +%Y%m%d).tar.gz data/

# 保留最近30天的备份
find . -name "data_backup_*.tar.gz" -mtime +30 -delete
```

---

## 总结

✅ **支持多种格式**
- 单文件
- 多文件列表
- 通配符
- 目录

✅ **自动处理**
- 文件发现
- 数据合并
- 时间排序
- 去重处理

✅ **灵活配置**
- JSON配置驱动
- 支持各种场景
- 易于扩展

现在你可以轻松地使用多个历史数据文件进行回测了！🎉
