---
description: è®­ç»ƒä¸€ä¸ªAI/MLæ¨¡å‹çš„å®Œæ•´æµç¨‹
---

# æ¨¡å‹è®­ç»ƒå·¥ä½œæµ

æœ¬æ–‡æ¡£å®šä¹‰äº†è®­ç»ƒ AI/ML æ¨¡å‹ï¼ˆå¦‚ LightGBMã€æ³¢åŠ¨ç‡é¢„æµ‹æ¨¡å‹ç­‰ï¼‰çš„æ ‡å‡†åŒ–æµç¨‹ã€‚

## ğŸ“ ç›¸å…³ç›®å½•

```
crypto_strategy_trading/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ mining/                        # ç‰¹å¾å·¥ç¨‹
â”‚   â”‚   â”œâ”€â”€ feature_factory.py         # ç‰¹å¾å·¥å‚
â”‚   â”‚   â””â”€â”€ volatility_miner.py        # æ³¢åŠ¨ç‡æŒ–æ˜
â”‚   â”‚
â”‚   â”œâ”€â”€ model/                         # æ¨¡å‹è®­ç»ƒå’Œå­˜å‚¨
â”‚   â”‚   â”œâ”€â”€ train_lgbm.py              # LightGBMè®­ç»ƒè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ lgbm_model_*.txt           # æ¨¡å‹æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ best_features_*.json       # æœ€ä½³ç‰¹å¾é…ç½®
â”‚   â”‚   â””â”€â”€ volatility_model_*.joblib  # æ¨¡å‹æƒé‡
â”‚   â”‚
â”‚   â”œâ”€â”€ optimization/{strategy}/       # å‚æ•°ä¼˜åŒ–
â”‚   â””â”€â”€ verification/{strategy}/       # æ¨¡å‹éªŒè¯
â”‚
â””â”€â”€ data/                              # è®­ç»ƒæ•°æ®
    â””â”€â”€ *.csv
```

---

## æ­¥éª¤ 1: å‡†å¤‡è®­ç»ƒæ•°æ®

### 1.1 æ•°æ®è¦æ±‚

- è‡³å°‘6ä¸ªæœˆçš„å†å²æ•°æ®
- åŒ…å« OHLCV ç­‰åŸºç¡€å­—æ®µ
- æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆæ— ç©ºå€¼ã€æ— å¼‚å¸¸å€¼ï¼‰

### 1.2 ä¸‹è½½æ•°æ®

```bash
# ä½¿ç”¨æ•°æ®ä¸‹è½½å·¥å…·
cd backtest/utils

# ä¸‹è½½ DOGEUSDT 5åˆ†é’Ÿæ•°æ®
python download_binance_data.py \
    --symbol DOGEUSDT \
    --interval 5m \
    --start 2023-01-01 \
    --end 2024-12-31
```

### 1.3 åˆå¹¶æ•°æ®

```bash
python backtest/utils/merge_data.py
```

---

## æ­¥éª¤ 2: ç‰¹å¾å·¥ç¨‹

### 2.1 ä½¿ç”¨ç‰¹å¾å·¥å‚

ç¼–è¾‘æˆ–ä½¿ç”¨ `ai/mining/feature_factory.py`:

```python
# ai/mining/feature_factory.py
import pandas as pd
import numpy as np

class FeatureFactory:
    """ç‰¹å¾å·¥å‚ - ç”Ÿæˆè®­ç»ƒç‰¹å¾"""
    
    def __init__(self, df: pd.DataFrame):
        self.df = df
        
    def add_technical_indicators(self):
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
        # EMA
        for period in [5, 10, 20, 50]:
            self.df[f'ema_{period}'] = self.df['close'].ewm(span=period).mean()
        
        # RSI
        delta = self.df['close'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(14).mean()
        avg_loss = loss.rolling(14).mean()
        self.df['rsi'] = 100 - (100 / (1 + avg_gain / avg_loss))
        
        # æ³¢åŠ¨ç‡
        self.df['volatility'] = self.df['close'].pct_change().rolling(20).std()
        
        # æˆäº¤é‡ç‰¹å¾
        self.df['volume_ma'] = self.df['vol'].rolling(20).mean()
        self.df['volume_ratio'] = self.df['vol'] / self.df['volume_ma']
        
        return self
    
    def add_labels(self, horizon=12, threshold=0.01):
        """æ·»åŠ æ ‡ç­¾ï¼ˆæœªæ¥æ”¶ç›Šæ–¹å‘ï¼‰"""
        future_return = self.df['close'].shift(-horizon) / self.df['close'] - 1
        self.df['label'] = np.where(future_return > threshold, 1,
                                    np.where(future_return < -threshold, -1, 0))
        return self
    
    def get_features(self):
        """è·å–ç‰¹å¾åˆ—è¡¨"""
        feature_cols = [col for col in self.df.columns 
                       if col not in ['open', 'high', 'low', 'close', 'vol', 
                                      'label', 'open_time']]
        return feature_cols
```

### 2.2 ç”Ÿæˆç‰¹å¾

```python
# ä½¿ç”¨ç‰¹å¾å·¥å‚
from ai.mining.feature_factory import FeatureFactory
import pandas as pd

df = pd.read_csv("data/DOGEUSDT-5m-merged.csv")
factory = FeatureFactory(df)
factory.add_technical_indicators().add_labels()

features = factory.get_features()
print(f"ç”Ÿæˆ {len(features)} ä¸ªç‰¹å¾")
```

---

## æ­¥éª¤ 3: è®­ç»ƒæ¨¡å‹

### 3.1 åˆ›å»ºè®­ç»ƒè„šæœ¬

åœ¨ `ai/model/train_lgbm.py` ä¸­ç¼–å†™ï¼š

```python
# ai/model/train_lgbm.py
import json
import lightgbm as lgb
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score

import sys
sys.path.insert(0, str(Path(__file__).resolve().parents[2]))
from ai.mining.feature_factory import FeatureFactory


def train_model(symbol: str = "DOGEUSDT"):
    """è®­ç»ƒ LightGBM æ¨¡å‹"""
    
    # 1. åŠ è½½æ•°æ®
    data_path = f"data/{symbol}-5m-merged.csv"
    df = pd.read_csv(data_path)
    print(f"åŠ è½½æ•°æ®: {len(df)} è¡Œ")
    
    # 2. ç”Ÿæˆç‰¹å¾
    factory = FeatureFactory(df)
    factory.add_technical_indicators().add_labels()
    features = factory.get_features()
    
    # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
    df_clean = df.dropna()
    X = df_clean[features]
    y = df_clean['label']
    
    # 4. åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, shuffle=False
    )
    
    # 5. è®­ç»ƒæ¨¡å‹
    train_data = lgb.Dataset(X_train, label=y_train)
    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    params = {
        'objective': 'multiclass',
        'num_class': 3,  # -1, 0, 1
        'metric': 'multi_logloss',
        'learning_rate': 0.05,
        'num_leaves': 31,
        'max_depth': 6,
        'min_data_in_leaf': 50,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1
    }
    
    model = lgb.train(
        params,
        train_data,
        num_boost_round=500,
        valid_sets=[test_data],
        callbacks=[lgb.early_stopping(50)]
    )
    
    # 6. è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test).argmax(axis=1)
    y_test_mapped = y_test.map({-1: 0, 0: 1, 1: 2})
    
    accuracy = accuracy_score(y_test_mapped, y_pred)
    f1 = f1_score(y_test_mapped, y_pred, average='weighted')
    print(f"å‡†ç¡®ç‡: {accuracy:.4f}, F1: {f1:.4f}")
    
    # 7. ä¿å­˜æ¨¡å‹
    model_path = f"ai/model/lgbm_model_{symbol}.txt"
    model.save_model(model_path)
    print(f"æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # 8. ä¿å­˜æœ€ä½³ç‰¹å¾
    importance = dict(zip(features, model.feature_importance()))
    top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:20]
    
    features_path = f"ai/model/best_features_{symbol}.json"
    Path(features_path).write_text(json.dumps({
        "features": [f[0] for f in top_features],
        "accuracy": accuracy,
        "f1_score": f1
    }, indent=2))
    print(f"ç‰¹å¾é…ç½®å·²ä¿å­˜: {features_path}")
    
    return model, accuracy


if __name__ == "__main__":
    train_model("DOGEUSDT")
```

### 3.2 è¿è¡Œè®­ç»ƒ

```bash
# è®­ç»ƒæ¨¡å‹
python ai/model/train_lgbm.py

# æŸ¥çœ‹è¾“å‡º
ls ai/model/
# lgbm_model_DOGEUSDT.txt
# best_features_DOGEUSDT.json
```

---

## æ­¥éª¤ 4: éªŒè¯æ¨¡å‹

### 4.1 åœ¨æ ·æœ¬å¤–æ•°æ®éªŒè¯

```python
# åŠ è½½æ¨¡å‹
import lightgbm as lgb

model = lgb.Booster(model_file="ai/model/lgbm_model_DOGEUSDT.txt")

# åœ¨æ–°æ•°æ®ä¸Šæµ‹è¯•
df_test = pd.read_csv("data/DOGEUSDT-5m-2025.csv")
# ... ç”Ÿæˆç‰¹å¾å¹¶é¢„æµ‹
```

### 4.2 å›æµ‹éªŒè¯

```bash
# å°†æ¨¡å‹é›†æˆåˆ°ç­–ç•¥ä¸­è¿›è¡Œå›æµ‹
python backtest/run_backtest.py --config backtest/configs/ai_strategy.json
```

---

## æ­¥éª¤ 5: é›†æˆåˆ°ç­–ç•¥

åœ¨ç­–ç•¥ä¸­ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼š

```python
# strategies/ai_strategy/strategy.py
import lightgbm as lgb
import json
from pathlib import Path

class AIStrategy:
    def __init__(self, model_path: str, features_path: str):
        self.model = lgb.Booster(model_file=model_path)
        self.features = json.loads(Path(features_path).read_text())["features"]
    
    def analyze(self, klines):
        # å‡†å¤‡ç‰¹å¾
        features = self._prepare_features(klines)
        
        # é¢„æµ‹
        probs = self.model.predict(features)
        prediction = probs.argmax()  # 0=ä¸‹è·Œ, 1=éœ‡è¡, 2=ä¸Šæ¶¨
        
        if prediction == 2:
            return {"signal": "buy", "reason": f"AIé¢„æµ‹ä¸Šæ¶¨, æ¦‚ç‡={probs[2]:.2f}"}
        elif prediction == 0:
            return {"signal": "sell", "reason": f"AIé¢„æµ‹ä¸‹è·Œ, æ¦‚ç‡={probs[0]:.2f}"}
        else:
            return {"signal": "hold", "reason": "AIé¢„æµ‹éœ‡è¡"}
```

---

## âœ… è®­ç»ƒæ£€æŸ¥æ¸…å•

- [ ] æ•°æ®è´¨é‡æ£€æŸ¥
- [ ] ç‰¹å¾å·¥ç¨‹å®Œæˆ
- [ ] è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†æ­£ç¡®
- [ ] æ¨¡å‹è®­ç»ƒå®Œæˆ
- [ ] è¯„ä¼°æŒ‡æ ‡æ»¡æ„
- [ ] æ ·æœ¬å¤–éªŒè¯é€šè¿‡
- [ ] æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜
- [ ] é›†æˆåˆ°ç­–ç•¥æµ‹è¯•

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ—¶é—´æ³„éœ²**: ç¡®ä¿è®­ç»ƒæ—¶ä¸ä½¿ç”¨æœªæ¥æ•°æ®
2. **è¿‡æ‹Ÿåˆ**: ä½¿ç”¨äº¤å‰éªŒè¯å’Œæ­£åˆ™åŒ–
3. **ç‰¹å¾é€‰æ‹©**: é€‰æ‹©æœ‰æ„ä¹‰çš„ç‰¹å¾ï¼Œé¿å…å™ªå£°
4. **æ¨¡å‹æ›´æ–°**: å®šæœŸä½¿ç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒ
5. **å›æµ‹éªŒè¯**: æ¨¡å‹æ•ˆæœéœ€è¦åœ¨å›æµ‹ä¸­éªŒè¯
