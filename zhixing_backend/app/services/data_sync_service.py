"""
æ•°æ®åŒæ­¥æœåŠ¡
è´Ÿè´£å®šæ—¶åŒæ­¥è‡ªé€‰è‚¡çš„Kçº¿æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“
"""
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from loguru import logger

from ..core.interfaces import (
    IMarketDataProvider, IStockRepository, IKLineRepository, KLineData
)


class DataSyncService:
    """æ•°æ®åŒæ­¥æœåŠ¡"""
    
    def __init__(
        self,
        market_data_provider: IMarketDataProvider,
        stock_repository: IStockRepository,
        kline_repository: IKLineRepository
    ):
        self.market_data_provider = market_data_provider
        self.stock_repository = stock_repository
        self.kline_repository = kline_repository
        self.is_syncing = False
        # æœ€è¿‘ä¸€æ¬¡åŒæ­¥ç»“æœï¼ˆå†…å­˜ä¿å­˜ï¼Œä¾¿äºå‰ç«¯æŸ¥çœ‹å¤±è´¥è¯¦æƒ…/é‡è¯•ï¼‰
        self._last_result: Optional[Dict[str, any]] = None
        self._last_sync_time: Optional[datetime] = None
    
    async def sync_all_watchlist_data(self, force_full_sync: bool = False) -> Dict[str, any]:
        """
        åŒæ­¥æ‰€æœ‰è‡ªé€‰è‚¡æ•°æ®
        
        Args:
            force_full_sync: æ˜¯å¦å¼ºåˆ¶å…¨é‡åŒæ­¥ï¼ˆå¦åˆ™å¢é‡åŒæ­¥ï¼‰
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if self.is_syncing:
            logger.warning("æ•°æ®åŒæ­¥æ­£åœ¨è¿›è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡åŒæ­¥")
            return {"status": "skipped", "reason": "sync_in_progress"}
        
        self.is_syncing = True
        sync_start_time = datetime.now()
        
        try:
            logger.info("ğŸ”„ å¼€å§‹åŒæ­¥è‡ªé€‰è‚¡æ•°æ®...")
            
            # 1. è·å–è‡ªé€‰è‚¡åˆ—è¡¨
            stocks = await self.stock_repository.get_all_stocks()
            if not stocks:
                logger.warning("è‡ªé€‰è‚¡åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€åŒæ­¥")
                return {"status": "skipped", "reason": "no_stocks"}
            
            symbols = [stock.code if hasattr(stock, 'code') else stock.symbol for stock in stocks]
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(symbols)} åªè‡ªé€‰è‚¡éœ€è¦åŒæ­¥: {', '.join(symbols)}")
            
            # 2. åŒæ­¥ç»“æœç»Ÿè®¡
            sync_results = {
                "total_stocks": len(symbols),
                "success_stocks": 0,
                "failed_stocks": 0,
                "daily_records": 0,
                "hourly_records": 0,
                "sync_type": "full" if force_full_sync else "incremental",
                "start_time": sync_start_time.isoformat(),
                "details": {}
            }
            
            # 3. é€ä¸ªåŒæ­¥è‚¡ç¥¨æ•°æ®
            for symbol in symbols:
                try:
                    stock_result = await self._sync_single_stock(symbol, force_full_sync)
                    sync_results["details"][symbol] = stock_result
                    
                    if stock_result["success"]:
                        sync_results["success_stocks"] += 1
                        sync_results["daily_records"] += stock_result["daily_count"]
                        sync_results["hourly_records"] += stock_result["hourly_count"]
                    else:
                        sync_results["failed_stocks"] += 1
                    
                    # é¿å…APIé™åˆ¶ï¼Œæ·»åŠ å»¶è¿Ÿ
                    await asyncio.sleep(0.2)
                    
                except Exception as e:
                    logger.error(f"åŒæ­¥è‚¡ç¥¨ {symbol} å¤±è´¥: {e}")
                    sync_results["failed_stocks"] += 1
                    sync_results["details"][symbol] = {
                        "success": False,
                        "error": str(e),
                        "daily_count": 0,
                        "hourly_count": 0
                    }
            
            # 4. å®Œæˆç»Ÿè®¡
            sync_end_time = datetime.now()
            sync_duration = (sync_end_time - sync_start_time).total_seconds()
            
            sync_results.update({
                "status": "completed",
                "end_time": sync_end_time.isoformat(),
                "duration_seconds": round(sync_duration, 2),
                "success_rate": round(sync_results["success_stocks"] / len(symbols) * 100, 1)
            })
            
            logger.info(f"âœ… æ•°æ®åŒæ­¥å®Œæˆ: {sync_results['success_stocks']}/{len(symbols)} æˆåŠŸ, "
                       f"æ—¥çº¿ {sync_results['daily_records']} æ¡, "
                       f"å°æ—¶çº¿ {sync_results['hourly_records']} æ¡, "
                       f"è€—æ—¶ {sync_duration:.1f}ç§’")
            # ä¿å­˜æœ€åä¸€æ¬¡ç»“æœ
            self._last_result = sync_results
            self._last_sync_time = sync_end_time
            return sync_results
            
        except Exception as e:
            logger.error(f"æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            self._last_result = {
                "status": "failed",
                "error": str(e),
                "end_time": datetime.now().isoformat()
            }
            self._last_sync_time = datetime.now()
            return self._last_result
        
        finally:
            self.is_syncing = False

    async def sync_specific_symbols(self, symbols: List[str], force_full_sync: bool = False) -> Dict[str, any]:
        """åªåŒæ­¥æŒ‡å®šè‚¡ç¥¨æ¸…å•ï¼ˆç”¨äºé‡è¯•å¤±è´¥é¡¹ï¼‰"""
        if self.is_syncing:
            return {"status": "skipped", "reason": "sync_in_progress"}

        self.is_syncing = True
        sync_start_time = datetime.now()
        try:
            results = {
                "total_stocks": len(symbols),
                "success_stocks": 0,
                "failed_stocks": 0,
                "daily_records": 0,
                "hourly_records": 0,
                "sync_type": "full" if force_full_sync else "incremental",
                "start_time": sync_start_time.isoformat(),
                "details": {},
            }
            for symbol in symbols:
                try:
                    stock_result = await self._sync_single_stock(symbol, force_full_sync)
                    results["details"][symbol] = stock_result
                    if stock_result.get("success"):
                        results["success_stocks"] += 1
                        results["daily_records"] += stock_result.get("daily_count", 0)
                        results["hourly_records"] += stock_result.get("hourly_count", 0)
                    else:
                        results["failed_stocks"] += 1
                    await asyncio.sleep(0.2)
                except Exception as e:
                    results["failed_stocks"] += 1
                    results["details"][symbol] = {"success": False, "error": str(e), "daily_count": 0, "hourly_count": 0}

            sync_end_time = datetime.now()
            duration = (sync_end_time - sync_start_time).total_seconds()
            results.update({
                "status": "completed",
                "end_time": sync_end_time.isoformat(),
                "duration_seconds": round(duration, 2),
                "success_rate": round((results["success_stocks"] / max(1, len(symbols))) * 100, 1),
            })
            self._last_result = results
            self._last_sync_time = sync_end_time
            return results
        except Exception as e:
            now = datetime.now()
            self._last_result = {"status": "failed", "error": str(e), "end_time": now.isoformat()}
            self._last_sync_time = now
            return self._last_result
        finally:
            self.is_syncing = False

    def get_last_result(self) -> Dict[str, any]:
        return self._last_result or {"status": "none"}

    def get_last_sync_time(self) -> Optional[str]:
        return self._last_sync_time.isoformat() if self._last_sync_time else None
    
    async def _sync_single_stock(self, symbol: str, force_full_sync: bool) -> Dict[str, any]:
        """åŒæ­¥å•åªè‚¡ç¥¨æ•°æ®"""
        try:
            logger.debug(f"ğŸ“¡ åŒæ­¥è‚¡ç¥¨ {symbol} æ•°æ®...")
            
            result = {
                "success": False,
                "daily_count": 0,
                "hourly_count": 0,
                "error": None
            }
            
            # 1. åŒæ­¥æ—¥çº¿æ•°æ®
            if force_full_sync:
                # å…¨é‡åŒæ­¥ï¼šè·å–1å¹´æ•°æ®
                daily_data = await self.market_data_provider.get_stock_data(symbol, "1y", "1d")
            else:
                # å¢é‡åŒæ­¥ï¼šä»…è·å–æœ¬åœ°æœ€æ–°æ—¶é—´ä¹‹åçš„æ•°æ®ï¼ˆå…œåº•30å¤©ï¼‰
                last_daily = await self.kline_repository.get_last_datetime(symbol, "1d")
                if last_daily:
                    # Yahoo provideræŒ‰ period/interval æ‹‰å–ï¼Œæ— æ³•æŒ‰æ—¶é—´è¿‡æ»¤ï¼Œè¿™é‡Œä»ç„¶å–30å¤©ï¼Œä¿å­˜æ—¶å»é‡
                    daily_data = await self.market_data_provider.get_stock_data(symbol, "30d", "1d")
                else:
                    daily_data = await self.market_data_provider.get_stock_data(symbol, "30d", "1d")
            
            if daily_data:
                daily_saved = await self._save_kline_data(symbol, daily_data, "1d")
                result["daily_count"] = daily_saved
                logger.debug(f"ğŸ“Š {symbol} æ—¥çº¿æ•°æ®: è·å– {len(daily_data)} æ¡, ä¿å­˜ {daily_saved} æ¡")
            
            # 2. åŒæ­¥å°æ—¶çº¿æ•°æ®
            if force_full_sync:
                # å…¨é‡åŒæ­¥ï¼šè·å–60å¤©å°æ—¶çº¿
                hourly_data = await self.market_data_provider.get_stock_data(symbol, "60d", "1h")
            else:
                # å¢é‡åŒæ­¥ï¼šä»…è·å–æœ¬åœ°æœ€æ–°æ—¶é—´ä¹‹åçš„æ•°æ®ï¼ˆå…œåº•7å¤©ï¼‰
                last_hourly = await self.kline_repository.get_last_datetime(symbol, "1h")
                if last_hourly:
                    hourly_data = await self.market_data_provider.get_stock_data(symbol, "7d", "1h")
                else:
                    hourly_data = await self.market_data_provider.get_stock_data(symbol, "7d", "1h")
            
            if hourly_data:
                hourly_saved = await self._save_kline_data(symbol, hourly_data, "1h")
                result["hourly_count"] = hourly_saved
                logger.debug(f"ğŸ“Š {symbol} å°æ—¶çº¿æ•°æ®: è·å– {len(hourly_data)} æ¡, ä¿å­˜ {hourly_saved} æ¡")
            
            result["success"] = True
            return result
            
        except Exception as e:
            logger.error(f"åŒæ­¥è‚¡ç¥¨ {symbol} å¤±è´¥: {e}")
            return {
                "success": False,
                "daily_count": 0,
                "hourly_count": 0,
                "error": str(e)
            }
    
    async def _save_kline_data(self, symbol: str, kline_data: List[KLineData], timeframe: str) -> int:
        """ä¿å­˜Kçº¿æ•°æ®åˆ°æ•°æ®åº“"""
        saved_count = 0
        
        for kline in kline_data:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ£€æŸ¥æ•°æ®åº“ï¼‰
                # è¿™é‡Œå‡è®¾æ•°æ®åº“æœ‰å»é‡æœºåˆ¶
                
                data_dict = {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'datetime': kline.datetime,
                    'open': kline.open,
                    'high': kline.high,
                    'low': kline.low,
                    'close': kline.close,
                    'volume': kline.volume,
                    'data_source': 'yahoo',
                    'sync_time': datetime.now()
                }
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                success = await self.kline_repository.save_kline_data(data_dict)
                if success:
                    saved_count += 1
                
            except Exception as e:
                logger.error(f"ä¿å­˜Kçº¿æ•°æ®å¤±è´¥: {e}")
                continue
        
        return saved_count
    
    async def get_sync_status(self) -> Dict[str, any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        return {
            "is_syncing": self.is_syncing,
            "last_sync_time": None,  # TODO: ä»æ•°æ®åº“è·å–
            "next_sync_time": None,  # TODO: è®¡ç®—ä¸‹æ¬¡åŒæ­¥æ—¶é—´
            "total_records": None,   # TODO: ä»æ•°æ®åº“ç»Ÿè®¡
        }
    
    async def cleanup_old_data(self, days_to_keep: int = 90) -> int:
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            deleted_count = await self.kline_repository.cleanup_old_data(cutoff_date)
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {deleted_count} æ¡è¿‡æœŸKçº¿æ•°æ®")
            return deleted_count
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
            return 0
