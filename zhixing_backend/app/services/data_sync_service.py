"""
æ•°æ®åŒæ­¥æœåŠ¡
è´Ÿè´£å®šæ—¶åŒæ­¥è‡ªé€‰è‚¡çš„Kçº¿æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“
"""
import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from loguru import logger

from ..core.interfaces import (
    IMarketDataProvider, IStockRepository, IKLineRepository, KLineData
)
from ..repositories.data_sync_task_repository import DataSyncTaskRepository


class DataSyncService:
    """æ•°æ®åŒæ­¥æœåŠ¡"""
    
    def __init__(
        self,
        market_data_provider: IMarketDataProvider,
        stock_repository: IStockRepository,
        kline_repository: IKLineRepository
    ):
        self.market_data_provider = market_data_provider
        self.stock_repository = stock_repository
        self.kline_repository = kline_repository
        self.task_repository = DataSyncTaskRepository()
        self.is_syncing = False
        # æœ€è¿‘ä¸€æ¬¡åŒæ­¥ç»“æœï¼ˆå†…å­˜ä¿å­˜ï¼Œä¾¿äºå‰ç«¯æŸ¥çœ‹å¤±è´¥è¯¦æƒ…/é‡è¯•ï¼‰
        self._last_result: Optional[Dict[str, any]] = None
        self._last_sync_time: Optional[datetime] = None
        self._current_task_id: Optional[str] = None
    
    async def sync_all_watchlist_data(
        self, 
        force_full_sync: bool = False,
        task_id: Optional[str] = None
    ) -> Dict[str, any]:
        """
        åŒæ­¥æ‰€æœ‰è‡ªé€‰è‚¡æ•°æ®
        
        Args:
            force_full_sync: æ˜¯å¦å¼ºåˆ¶å…¨é‡åŒæ­¥ï¼ˆå¦åˆ™å¢é‡åŒæ­¥ï¼‰
            task_id: ä»»åŠ¡IDï¼Œå¦‚æœæä¾›åˆ™æ›´æ–°ä»»åŠ¡çŠ¶æ€
        
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if self.is_syncing:
            logger.warning("æ•°æ®åŒæ­¥æ­£åœ¨è¿›è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡åŒæ­¥")
            return {"status": "skipped", "reason": "sync_in_progress"}
        
        self.is_syncing = True
        self._current_task_id = task_id
        sync_start_time = datetime.now()
        
        # å¦‚æœæœ‰ä»»åŠ¡IDï¼Œæ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        if task_id:
            await self.task_repository.update_task(
                task_id, 
                status='running',
                progress=0.0
            )
        
        try:
            logger.info("ğŸ”„ å¼€å§‹åŒæ­¥è‡ªé€‰è‚¡æ•°æ®...")
            
            # 1. è·å–è‡ªé€‰è‚¡åˆ—è¡¨
            stocks = await self.stock_repository.get_all_stocks()
            if not stocks:
                logger.warning("è‡ªé€‰è‚¡åˆ—è¡¨ä¸ºç©ºï¼Œæ— éœ€åŒæ­¥")
                result = {"status": "skipped", "reason": "no_stocks"}
                
                if task_id:
                    await self.task_repository.update_task(
                        task_id,
                        status='completed',
                        end_time=datetime.now(),
                        result_summary=result
                    )
                
                return result
            
            symbols = [stock.code if hasattr(stock, 'code') else stock.symbol for stock in stocks]
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(symbols)} åªè‡ªé€‰è‚¡éœ€è¦åŒæ­¥: {', '.join(symbols)}")
            
            # è®¾ç½®ä»»åŠ¡æ€»è‚¡ç¥¨æ•°é‡
            if task_id:
                await self.task_repository.set_task_total_stocks(task_id, len(symbols))
            
            # 2. åŒæ­¥ç»“æœç»Ÿè®¡
            sync_results = {
                "total_stocks": len(symbols),
                "success_stocks": 0,
                "failed_stocks": 0,
                "daily_records": 0,
                "hourly_records": 0,
                "sync_type": "full" if force_full_sync else "incremental",
                "start_time": sync_start_time.isoformat(),
                "details": {}
            }
            
            # 3. é€ä¸ªåŒæ­¥è‚¡ç¥¨æ•°æ®
            for i, symbol in enumerate(symbols):
                try:
                    stock_result = await self._sync_single_stock(symbol, force_full_sync)
                    sync_results["details"][symbol] = stock_result
                    
                    success = stock_result["success"]
                    daily_count = stock_result.get("daily_count", 0)
                    hourly_count = stock_result.get("hourly_count", 0)
                    
                    if success:
                        sync_results["success_stocks"] += 1
                        sync_results["daily_records"] += daily_count
                        sync_results["hourly_records"] += hourly_count
                    else:
                        sync_results["failed_stocks"] += 1
                    
                    # æ›´æ–°ä»»åŠ¡è¿›åº¦
                    if task_id:
                        await self.task_repository.increment_processed_stocks(
                            task_id, 
                            success=success,
                            daily_count=daily_count,
                            hourly_count=hourly_count
                        )
                    
                    # é¿å…APIé™åˆ¶ï¼Œæ·»åŠ å»¶è¿Ÿ
                    await asyncio.sleep(0.2)
                    
                except Exception as e:
                    logger.error(f"åŒæ­¥è‚¡ç¥¨ {symbol} å¤±è´¥: {e}")
                    sync_results["failed_stocks"] += 1
                    sync_results["details"][symbol] = {
                        "success": False,
                        "error": str(e),
                        "daily_count": 0,
                        "hourly_count": 0
                    }
                    
                    # æ›´æ–°ä»»åŠ¡è¿›åº¦ï¼ˆå¤±è´¥ï¼‰
                    if task_id:
                        await self.task_repository.increment_processed_stocks(
                            task_id, 
                            success=False
                        )
            
            # 4. å®Œæˆç»Ÿè®¡
            sync_end_time = datetime.now()
            sync_duration = (sync_end_time - sync_start_time).total_seconds()
            
            sync_results.update({
                "status": "completed",
                "end_time": sync_end_time.isoformat(),
                "duration_seconds": round(sync_duration, 2),
                "success_rate": round(sync_results["success_stocks"] / len(symbols) * 100, 1) if symbols else 0
            })
            
            # æ›´æ–°ä»»åŠ¡å®ŒæˆçŠ¶æ€
            if task_id:
                await self.task_repository.update_task(
                    task_id,
                    status='completed',
                    progress=100.0,
                    end_time=sync_end_time,
                    duration_seconds=sync_duration,
                    result_summary=sync_results,
                    sync_details=sync_results["details"]
                )
            
            logger.info(f"âœ… æ•°æ®åŒæ­¥å®Œæˆ: {sync_results['success_stocks']}/{len(symbols)} æˆåŠŸ, "
                       f"æ—¥çº¿ {sync_results['daily_records']} æ¡, "
                       f"å°æ—¶çº¿ {sync_results['hourly_records']} æ¡, "
                       f"è€—æ—¶ {sync_duration:.1f}ç§’")
            
            # ä¿å­˜æœ€åä¸€æ¬¡ç»“æœ
            self._last_result = sync_results
            self._last_sync_time = sync_end_time
            return sync_results
            
        except Exception as e:
            logger.error(f"æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            error_result = {
                "status": "failed",
                "error": str(e),
                "end_time": datetime.now().isoformat()
            }
            
            # æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€
            if task_id:
                await self.task_repository.update_task(
                    task_id,
                    status='failed',
                    end_time=datetime.now(),
                    error_details={"error": str(e)}
                )
            
            self._last_result = error_result
            self._last_sync_time = datetime.now()
            return self._last_result
        
        finally:
            self.is_syncing = False
            self._current_task_id = None

    async def sync_specific_symbols(self, symbols: List[str], force_full_sync: bool = False) -> Dict[str, any]:
        """åªåŒæ­¥æŒ‡å®šè‚¡ç¥¨æ¸…å•ï¼ˆç”¨äºé‡è¯•å¤±è´¥é¡¹ï¼‰"""
        if self.is_syncing:
            return {"status": "skipped", "reason": "sync_in_progress"}

        self.is_syncing = True
        sync_start_time = datetime.now()
        try:
            results = {
                "total_stocks": len(symbols),
                "success_stocks": 0,
                "failed_stocks": 0,
                "daily_records": 0,
                "hourly_records": 0,
                "sync_type": "full" if force_full_sync else "incremental",
                "start_time": sync_start_time.isoformat(),
                "details": {},
            }
            for symbol in symbols:
                try:
                    stock_result = await self._sync_single_stock(symbol, force_full_sync)
                    results["details"][symbol] = stock_result
                    if stock_result.get("success"):
                        results["success_stocks"] += 1
                        results["daily_records"] += stock_result.get("daily_count", 0)
                        results["hourly_records"] += stock_result.get("hourly_count", 0)
                    else:
                        results["failed_stocks"] += 1
                    await asyncio.sleep(0.2)
                except Exception as e:
                    results["failed_stocks"] += 1
                    results["details"][symbol] = {"success": False, "error": str(e), "daily_count": 0, "hourly_count": 0}

            sync_end_time = datetime.now()
            duration = (sync_end_time - sync_start_time).total_seconds()
            results.update({
                "status": "completed",
                "end_time": sync_end_time.isoformat(),
                "duration_seconds": round(duration, 2),
                "success_rate": round((results["success_stocks"] / max(1, len(symbols))) * 100, 1),
            })
            self._last_result = results
            self._last_sync_time = sync_end_time
            return results
        except Exception as e:
            now = datetime.now()
            self._last_result = {"status": "failed", "error": str(e), "end_time": now.isoformat()}
            self._last_sync_time = now
            return self._last_result
        finally:
            self.is_syncing = False

    def get_last_result(self) -> Dict[str, any]:
        return self._last_result or {"status": "none"}

    def get_last_sync_time(self) -> Optional[str]:
        return self._last_sync_time.isoformat() if self._last_sync_time else None
    
    async def _sync_single_stock(self, symbol: str, force_full_sync: bool) -> Dict[str, any]:
        """åŒæ­¥å•åªè‚¡ç¥¨æ•°æ®"""
        try:
            logger.debug(f"ğŸ“¡ åŒæ­¥è‚¡ç¥¨ {symbol} æ•°æ®...")
            
            result = {
                "success": False,
                "daily_count": 0,
                "hourly_count": 0,
                "error": None
            }
            
            # 1. åŒæ­¥æ—¥çº¿æ•°æ®
            if force_full_sync:
                # å…¨é‡åŒæ­¥ï¼šè·å–2å¹´æ•°æ®ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ç”¨äºæŠ€æœ¯åˆ†æ
                daily_data = await self.market_data_provider.get_stock_data(symbol, "2y", "1d")
            else:
                # å¢é‡åŒæ­¥ï¼šè·å–æ›´å¤šå†å²æ•°æ®ï¼ˆå…œåº•200å¤©ï¼‰ï¼Œç¡®ä¿ç­–ç•¥æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æ
                last_daily = await self.kline_repository.get_last_datetime(symbol, "1d")
                if last_daily:
                    # Yahoo provideræŒ‰ period/interval æ‹‰å–ï¼Œæ— æ³•æŒ‰æ—¶é—´è¿‡æ»¤ï¼Œè¿™é‡Œå–200å¤©ï¼Œä¿å­˜æ—¶å»é‡
                    daily_data = await self.market_data_provider.get_stock_data(symbol, "200d", "1d")
                else:
                    # é¦–æ¬¡åŒæ­¥æ—¶è·å–è¶³å¤Ÿçš„å†å²æ•°æ®
                    daily_data = await self.market_data_provider.get_stock_data(symbol, "1y", "1d")
            
            if daily_data:
                daily_saved = await self._save_kline_data(symbol, daily_data, "1d")
                result["daily_count"] = daily_saved
                logger.debug(f"ğŸ“Š {symbol} æ—¥çº¿æ•°æ®: è·å– {len(daily_data)} æ¡, ä¿å­˜ {daily_saved} æ¡")
            
            # 2. åŒæ­¥å°æ—¶çº¿æ•°æ®
            if force_full_sync:
                # å…¨é‡åŒæ­¥ï¼šè·å–æ›´å¤šå°æ—¶çº¿æ•°æ®ï¼ˆçº¦6ä¸ªæœˆï¼‰ï¼Œç¡®ä¿æŠ€æœ¯åˆ†ææœ‰è¶³å¤Ÿçš„æ•°æ®
                hourly_data = await self.market_data_provider.get_stock_data(symbol, "180d", "1h")
            else:
                # å¢é‡åŒæ­¥ï¼šè·å–æ›´å¤šå†å²æ•°æ®ï¼ˆå…œåº•30å¤©ï¼‰ï¼Œç¡®ä¿ç­–ç•¥æœ‰è¶³å¤Ÿçš„å°æ—¶çº¿æ•°æ®è¿›è¡Œåˆ†æ
                last_hourly = await self.kline_repository.get_last_datetime(symbol, "1h")
                if last_hourly:
                    hourly_data = await self.market_data_provider.get_stock_data(symbol, "30d", "1h")
                else:
                    # é¦–æ¬¡åŒæ­¥æ—¶è·å–è¶³å¤Ÿçš„å†å²æ•°æ®
                    hourly_data = await self.market_data_provider.get_stock_data(symbol, "90d", "1h")
            
            if hourly_data:
                hourly_saved = await self._save_kline_data(symbol, hourly_data, "1h")
                result["hourly_count"] = hourly_saved
                logger.debug(f"ğŸ“Š {symbol} å°æ—¶çº¿æ•°æ®: è·å– {len(hourly_data)} æ¡, ä¿å­˜ {hourly_saved} æ¡")
            
            result["success"] = True
            return result
            
        except Exception as e:
            logger.error(f"åŒæ­¥è‚¡ç¥¨ {symbol} å¤±è´¥: {e}")
            return {
                "success": False,
                "daily_count": 0,
                "hourly_count": 0,
                "error": str(e)
            }
    
    async def _save_kline_data(self, symbol: str, kline_data: List[KLineData], timeframe: str) -> int:
        """ä¿å­˜Kçº¿æ•°æ®åˆ°æ•°æ®åº“"""
        saved_count = 0
        
        for kline in kline_data:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ£€æŸ¥æ•°æ®åº“ï¼‰
                # è¿™é‡Œå‡è®¾æ•°æ®åº“æœ‰å»é‡æœºåˆ¶
                
                data_dict = {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'datetime': kline.datetime,
                    'open': kline.open,
                    'high': kline.high,
                    'low': kline.low,
                    'close': kline.close,
                    'volume': kline.volume,
                    'data_source': 'yahoo',
                    'sync_time': datetime.now()
                }
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                success = await self.kline_repository.save_kline_data(data_dict)
                if success:
                    saved_count += 1
                
            except Exception as e:
                logger.error(f"ä¿å­˜Kçº¿æ•°æ®å¤±è´¥: {e}")
                continue
        
        return saved_count
    
    async def get_sync_status(self) -> Dict[str, any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        # è·å–è¿è¡Œä¸­çš„ä»»åŠ¡
        running_tasks = await self.task_repository.get_running_tasks()
        current_task = running_tasks[0] if running_tasks else None
        
        # è·å–æœ€è¿‘çš„ä»»åŠ¡
        recent_tasks = await self.task_repository.get_recent_tasks(1)
        last_task = recent_tasks[0] if recent_tasks else None
        
        return {
            "is_syncing": self.is_syncing,
            "current_task_id": self._current_task_id,
            "current_task": {
                "task_id": current_task.task_id,
                "status": current_task.status,
                "progress": current_task.progress,
                "processed_stocks": current_task.processed_stocks,
                "total_stocks": current_task.total_stocks,
                "success_stocks": current_task.success_stocks,
                "failed_stocks": current_task.failed_stocks,
                "start_time": current_task.start_time.isoformat() if current_task.start_time else None
            } if current_task else None,
            "last_task": {
                "task_id": last_task.task_id,
                "status": last_task.status,
                "progress": last_task.progress,
                "end_time": last_task.end_time.isoformat() if last_task.end_time else None,
                "duration_seconds": last_task.duration_seconds,
                "success_stocks": last_task.success_stocks,
                "failed_stocks": last_task.failed_stocks,
                "total_stocks": last_task.total_stocks
            } if last_task else None,
            "last_sync_time": self._last_sync_time.isoformat() if self._last_sync_time else None,
        }
    
    async def get_task_status(self, task_id: str) -> Optional[Dict[str, any]]:
        """è·å–æŒ‡å®šä»»åŠ¡çš„çŠ¶æ€"""
        task = await self.task_repository.get_task(task_id)
        if not task:
            return None
        
        return {
            "task_id": task.task_id,
            "status": task.status,
            "progress": task.progress,
            "total_stocks": task.total_stocks,
            "processed_stocks": task.processed_stocks,
            "success_stocks": task.success_stocks,
            "failed_stocks": task.failed_stocks,
            "daily_records": task.daily_records,
            "hourly_records": task.hourly_records,
            "task_type": task.task_type,
            "force_full_sync": task.force_full_sync,
            "start_time": task.start_time.isoformat() if task.start_time else None,
            "end_time": task.end_time.isoformat() if task.end_time else None,
            "duration_seconds": task.duration_seconds,
            "result_summary": task.result_summary,
            "error_details": task.error_details,
            "created_at": task.created_at.isoformat() if task.created_at else None,
            "updated_at": task.updated_at.isoformat() if task.updated_at else None
        }
    
    async def create_sync_task(
        self, 
        task_type: str = "incremental", 
        force_full_sync: bool = False,
        target_symbols: Optional[List[str]] = None
    ) -> str:
        """åˆ›å»ºæ–°çš„æ•°æ®åŒæ­¥ä»»åŠ¡"""
        return await self.task_repository.create_task(
            task_type=task_type,
            force_full_sync=force_full_sync,
            target_symbols=target_symbols,
            trigger_source='manual'
        )
    
    async def cleanup_old_data(self, days_to_keep: int = 90) -> int:
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            deleted_count = await self.kline_repository.cleanup_old_data(cutoff_date)
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {deleted_count} æ¡è¿‡æœŸKçº¿æ•°æ®")
            return deleted_count
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
            return 0
