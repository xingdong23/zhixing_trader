# è‚¡ç¥¨æ± è‡ªåŠ¨åŒ–å‡†å¤‡æ–¹æ¡ˆ

## ğŸ¯ ç›®æ ‡

è‡ªåŠ¨è·å–600-800åªä¸­å°ç›˜ç¾è‚¡ï¼Œç”¨äºæ¯æ—¥æ‰«æã€‚

**ä¸éœ€è¦æ‰‹åŠ¨ç»´æŠ¤ï¼**

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | éš¾åº¦ | æ—¶é—´ | è‚¡ç¥¨æ•° | æ¨èåº¦ |
|------|------|------|--------|--------|
| æ–¹æ¡ˆ1ï¼šETFæŒä»“è·å– | â­ | 10åˆ†é’Ÿ | 500-800 | â­â­â­â­â­ |
| æ–¹æ¡ˆ2ï¼šWikipediaçˆ¬å– | â­â­ | 30åˆ†é’Ÿ | 2500+ | â­â­â­â­ |
| æ–¹æ¡ˆ3ï¼šFinnhubç­›é€‰ | â­â­ | 20åˆ†é’Ÿ | å¯å®šåˆ¶ | â­â­â­â­ |
| æ–¹æ¡ˆ4ï¼šæ‰‹åŠ¨ç²¾é€‰ | â­â­â­â­â­ | æ•°å°æ—¶ | è‡ªå®šä¹‰ | â­ |

---

## æ–¹æ¡ˆ1ï¼šä»ETFæŒä»“è·å–ï¼ˆæ¨èï¼‰â­â­â­â­â­

### åŸç†

è®¸å¤šETFä¸“æ³¨äºç‰¹å®šä¸»é¢˜ï¼Œå®ƒä»¬çš„æŒä»“å°±æ˜¯æœ€å¥½çš„è‚¡ç¥¨æ± ï¼

### ç›®æ ‡ETFåˆ—è¡¨

```python
TARGET_ETFS = {
    # ç”Ÿç‰©åŒ»è¯
    "IBB": "iShares Biotechnology ETF",           # ~250åª
    "XBI": "SPDR Biotech ETF",                    # ~130åª
    
    # æ¸…æ´èƒ½æº/ç”µåŠ¨è½¦
    "ICLN": "iShares Clean Energy ETF",           # ~100åª
    "TAN": "Invesco Solar ETF",                   # ~50åª
    "LIT": "Global X Lithium ETF",                # ~40åª
    
    # ç§‘æŠ€/åŠå¯¼ä½“
    "SOXX": "iShares Semiconductor ETF",          # ~30åª
    "ARKK": "ARK Innovation ETF",                 # ~40åª
    "ARKG": "ARK Genomic Revolution ETF",         # ~50åª
    
    # é‡‘èç§‘æŠ€
    "FINX": "Global X FinTech ETF",               # ~50åª
    
    # äº‘è®¡ç®—/SaaS
    "WCLD": "WisdomTree Cloud Computing ETF",     # ~60åª
    
    # å°ç›˜è‚¡
    "IWM": "iShares Russell 2000 ETF",            # ~2000åª
    "VB": "Vanguard Small-Cap ETF",               # ~1400åª
}

# å»é‡åé¢„è®¡ï¼š600-1000åªè‚¡ç¥¨
```

### å®ç°ä»£ç 

```python
# scripts/init_stock_universe_from_etfs.py

import yfinance as yf
import pandas as pd
from loguru import logger

def get_etf_holdings(etf_symbol: str) -> list:
    """
    è·å–ETFæŒä»“è‚¡ç¥¨åˆ—è¡¨
    
    æ–¹æ³•1: ä½¿ç”¨yfinanceï¼ˆç®€å•ä½†å¯èƒ½ä¸å®Œæ•´ï¼‰
    """
    try:
        etf = yf.Ticker(etf_symbol)
        
        # è·å–ETFæŒä»“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # æ³¨æ„ï¼šyfinanceå¯èƒ½æ— æ³•è·å–æ‰€æœ‰ETFçš„æŒä»“
        holdings = etf.get_institutional_holders()
        
        # å¦‚æœyfinanceä¸æ”¯æŒï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        return get_etf_holdings_from_web(etf_symbol)
    
    except Exception as e:
        logger.error(f"è·å–{etf_symbol}æŒä»“å¤±è´¥: {e}")
        return []

def get_etf_holdings_from_web(etf_symbol: str) -> list:
    """
    ä»ETFå®˜ç½‘çˆ¬å–æŒä»“ï¼ˆæ›´å¯é ï¼‰
    
    ä¸»è¦æ¥æºï¼š
    1. iShares ETF: https://www.ishares.com/
    2. SPDR ETF: https://www.ssga.com/
    3. ARK ETF: https://ark-funds.com/
    """
    import requests
    from bs4 import BeautifulSoup
    
    # ä¸åŒETFæä¾›å•†çš„URLæ¨¡æ¿
    urls = {
        "IBB": "https://www.ishares.com/us/products/239699/ishares-nasdaq-biotechnology-etf",
        "ICLN": "https://www.ishares.com/us/products/239738/ishares-global-clean-energy-etf",
        "ARKK": "https://ark-funds.com/arkk",
        # ... æ›´å¤š
    }
    
    if etf_symbol not in urls:
        logger.warning(f"{etf_symbol} URLæœªé…ç½®")
        return []
    
    try:
        # çˆ¬å–é¡µé¢
        response = requests.get(urls[etf_symbol])
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # è§£ææŒä»“è¡¨æ ¼ï¼ˆæ¯ä¸ªETFæä¾›å•†æ ¼å¼ä¸åŒï¼‰
        holdings = parse_holdings_table(soup, etf_symbol)
        
        return holdings
    
    except Exception as e:
        logger.error(f"çˆ¬å–{etf_symbol}æŒä»“å¤±è´¥: {e}")
        return []

def parse_holdings_table(soup, etf_symbol):
    """è§£ææŒä»“è¡¨æ ¼"""
    # è¿™é‡Œéœ€è¦é’ˆå¯¹ä¸åŒETFæä¾›å•†å®šåˆ¶è§£æé€»è¾‘
    # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦è¡¥å……
    return []

async def build_stock_universe():
    """æ„å»ºè‚¡ç¥¨æ± """
    
    all_stocks = set()
    
    # 1. ä»å¤šä¸ªETFè·å–æŒä»“
    target_etfs = ["IBB", "XBI", "ICLN", "TAN", "SOXX", "ARKK", "ARKG"]
    
    for etf_symbol in target_etfs:
        logger.info(f"è·å– {etf_symbol} æŒä»“...")
        holdings = get_etf_holdings(etf_symbol)
        all_stocks.update(holdings)
        logger.info(f"  è·å¾— {len(holdings)} åªè‚¡ç¥¨")
    
    # 2. è¿‡æ»¤æ¡ä»¶
    filtered_stocks = []
    
    for symbol in all_stocks:
        try:
            # è·å–è‚¡ç¥¨ä¿¡æ¯
            stock = yf.Ticker(symbol)
            info = stock.info
            
            # ç­›é€‰æ¡ä»¶
            market_cap = info.get('marketCap', 0)
            price = info.get('currentPrice', 0)
            
            # å¸‚å€¼ï¼š5äº¿-100äº¿ç¾å…ƒ
            if 500_000_000 <= market_cap <= 10_000_000_000:
                # ä»·æ ¼ï¼š$5-$150
                if 5 <= price <= 150:
                    filtered_stocks.append({
                        'symbol': symbol,
                        'name': info.get('shortName', ''),
                        'sector': info.get('sector', ''),
                        'industry': info.get('industry', ''),
                        'market_cap': market_cap,
                        'price': price,
                    })
        
        except Exception as e:
            logger.error(f"å¤„ç† {symbol} å¤±è´¥: {e}")
    
    logger.info(f"ç­›é€‰åè‚¡ç¥¨æ•°: {len(filtered_stocks)}")
    
    # 3. ä¿å­˜åˆ°æ•°æ®åº“
    save_to_database(filtered_stocks)
    
    # 4. å¯¼å‡ºåˆ°JSONæ–‡ä»¶ï¼ˆå¤‡ä»½ï¼‰
    import json
    with open('data/us_stock_universe.json', 'w') as f:
        json.dump(filtered_stocks, f, indent=2)
    
    logger.info(f"âœ… è‚¡ç¥¨æ± æ„å»ºå®Œæˆ: {len(filtered_stocks)} åªè‚¡ç¥¨")

if __name__ == "__main__":
    import asyncio
    asyncio.run(build_stock_universe())
```

---

## æ–¹æ¡ˆ2ï¼šä»Wikipediaè·å–ï¼ˆæœ€ç®€å•ï¼‰â­â­â­â­â­

### Russell 2000æˆåˆ†è‚¡

Wikipediaæœ‰ç°æˆçš„Russell 2000åˆ—è¡¨ï¼

```python
# scripts/get_russell2000_from_wikipedia.py

import pandas as pd
from loguru import logger

def get_russell2000_stocks():
    """
    ä»Wikipediaè·å–Russell 2000æˆåˆ†è‚¡
    """
    try:
        # æ–¹æ³•1: ç›´æ¥è¯»å–Wikipediaè¡¨æ ¼
        url = "https://en.wikipedia.org/wiki/Russell_2000_Index"
        
        # pandaså¯ä»¥ç›´æ¥è¯»å–HTMLè¡¨æ ¼
        tables = pd.read_html(url)
        
        # Russell 2000è¡¨æ ¼é€šå¸¸æ˜¯ç¬¬ä¸€ä¸ª
        df = tables[0]
        
        # æå–è‚¡ç¥¨ä»£ç åˆ—ï¼ˆé€šå¸¸å« 'Ticker' æˆ– 'Symbol'ï¼‰
        if 'Ticker' in df.columns:
            symbols = df['Ticker'].tolist()
        elif 'Symbol' in df.columns:
            symbols = df['Symbol'].tolist()
        else:
            logger.warning("æœªæ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—")
            return []
        
        logger.info(f"âœ… è·å–åˆ° {len(symbols)} åªRussell 2000æˆåˆ†è‚¡")
        return symbols
    
    except Exception as e:
        logger.error(f"è·å–Russell 2000å¤±è´¥: {e}")
        return []

def get_nasdaq100_stocks():
    """ä»Wikipediaè·å–NASDAQ 100"""
    url = "https://en.wikipedia.org/wiki/Nasdaq-100"
    tables = pd.read_html(url)
    df = tables[4]  # NASDAQ-100é€šå¸¸åœ¨ç¬¬5ä¸ªè¡¨æ ¼
    return df['Ticker'].tolist()

def get_sp600_stocks():
    """è·å–SP600ï¼ˆå°ç›˜è‚¡ï¼‰"""
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_600_companies"
    tables = pd.read_html(url)
    df = tables[0]
    return df['Symbol'].tolist()

async def build_from_wikipedia():
    """ä»Wikipediaæ„å»ºè‚¡ç¥¨æ± """
    
    all_symbols = set()
    
    # 1. Russell 2000ï¼ˆå°ç›˜è‚¡ï¼‰
    logger.info("è·å–Russell 2000...")
    all_symbols.update(get_russell2000_stocks())
    
    # 2. SP600ï¼ˆå°ç›˜è‚¡ï¼‰
    logger.info("è·å–SP600...")
    all_symbols.update(get_sp600_stocks())
    
    # 3. NASDAQ 100ï¼ˆç§‘æŠ€è‚¡ï¼‰
    logger.info("è·å–NASDAQ 100...")
    all_symbols.update(get_nasdaq100_stocks())
    
    logger.info(f"å»é‡åæ€»æ•°: {len(all_symbols)}")
    
    # 4. è·å–è¯¦ç»†ä¿¡æ¯å¹¶ç­›é€‰
    filtered_stocks = []
    
    for symbol in all_symbols:
        try:
            stock = yf.Ticker(symbol)
            info = stock.info
            
            market_cap = info.get('marketCap', 0)
            price = info.get('currentPrice', 0)
            
            # ç­›é€‰ï¼š5äº¿-100äº¿å¸‚å€¼
            if 500_000_000 <= market_cap <= 10_000_000_000:
                filtered_stocks.append({
                    'symbol': symbol,
                    'name': info.get('shortName', ''),
                    'sector': info.get('sector', ''),
                    'industry': info.get('industry', ''),
                    'market_cap': market_cap,
                    'price': price,
                })
                
                # è¿›åº¦æ˜¾ç¤º
                if len(filtered_stocks) % 50 == 0:
                    logger.info(f"å·²å¤„ç†: {len(filtered_stocks)} åª...")
        
        except Exception as e:
            logger.debug(f"è·³è¿‡ {symbol}: {e}")
    
    logger.info(f"âœ… ç­›é€‰å®Œæˆ: {len(filtered_stocks)} åªè‚¡ç¥¨")
    
    # 5. ä¿å­˜
    save_to_database(filtered_stocks)
    
    import json
    with open('data/us_stock_universe.json', 'w') as f:
        json.dump(filtered_stocks, f, indent=2)

if __name__ == "__main__":
    import asyncio
    asyncio.run(build_from_wikipedia())
```

---

## æ–¹æ¡ˆ3ï¼šä½¿ç”¨Finnhub APIç­›é€‰ â­â­â­â­

### ç›´æ¥ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨

```python
# scripts/screen_stocks_with_finnhub.py

from app.utils.market_data_helper import FinnhubProvider
from loguru import logger

async def screen_stocks_from_finnhub():
    """ä½¿ç”¨Finnhubç­›é€‰è‚¡ç¥¨"""
    
    provider = FinnhubProvider(api_key="YOUR_API_KEY")
    
    all_stocks = []
    
    # æŒ‰sectorç­›é€‰
    sectors = [
        "Healthcare",
        "Technology", 
        "Energy",
        "Consumer Cyclical",
        "Industrials",
    ]
    
    for sector in sectors:
        logger.info(f"ç­›é€‰æ¿å—: {sector}")
        
        # Finnhubç­›é€‰æ¡ä»¶
        results = await provider.screen_stocks({
            "exchange": "US",
            "sector": sector,
            "marketCapMoreThan": 500_000_000,      # 5äº¿ç¾å…ƒ
            "marketCapLessThan": 10_000_000_000,   # 100äº¿ç¾å…ƒ
            "priceMoreThan": 5,
            "priceLessThan": 150,
            "volumeMoreThan": 100_000,             # æ—¥å‡æˆäº¤é‡>10ä¸‡
        })
        
        all_stocks.extend(results)
        logger.info(f"  è·å¾— {len(results)} åªè‚¡ç¥¨")
        
        # é™æµ
        await asyncio.sleep(1)
    
    # å»é‡
    unique_stocks = {s['symbol']: s for s in all_stocks}.values()
    
    logger.info(f"âœ… æ€»è®¡ {len(unique_stocks)} åªè‚¡ç¥¨")
    
    # ä¿å­˜
    save_to_database(list(unique_stocks))
    
    return list(unique_stocks)
```

---

## ğŸš€ æ¨èå®æ–½æ–¹æ¡ˆï¼ˆæœ€å¿«ï¼‰

### æ­¥éª¤1ï¼šä½¿ç”¨Wikipediaï¼ˆ10åˆ†é’Ÿï¼‰

```bash
cd zhixing_backend
python scripts/init_stock_universe.py
```

```python
# scripts/init_stock_universe.py

import pandas as pd
import yfinance as yf
from loguru import logger
from sqlalchemy import create_engine
from app.config import settings

def get_stocks_from_wikipedia():
    """ä»Wikipediaè·å–å¤šä¸ªæŒ‡æ•°çš„è‚¡ç¥¨"""
    
    all_symbols = set()
    
    # 1. Russell 2000
    try:
        url = "https://en.wikipedia.org/wiki/Russell_2000_Index"
        tables = pd.read_html(url)
        df = tables[0]
        symbols = df['Ticker'].tolist() if 'Ticker' in df.columns else df['Symbol'].tolist()
        all_symbols.update(symbols)
        logger.info(f"âœ… Russell 2000: {len(symbols)} åª")
    except Exception as e:
        logger.error(f"Russell 2000å¤±è´¥: {e}")
    
    # 2. SP600
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_600_companies"
        tables = pd.read_html(url)
        df = tables[0]
        symbols = df['Symbol'].tolist()
        all_symbols.update(symbols)
        logger.info(f"âœ… SP600: {len(symbols)} åª")
    except Exception as e:
        logger.error(f"SP600å¤±è´¥: {e}")
    
    # 3. NASDAQ 100
    try:
        url = "https://en.wikipedia.org/wiki/Nasdaq-100"
        tables = pd.read_html(url)
        df = tables[4]
        symbols = df['Ticker'].tolist()
        all_symbols.update(symbols)
        logger.info(f"âœ… NASDAQ 100: {len(symbols)} åª")
    except Exception as e:
        logger.error(f"NASDAQ 100å¤±è´¥: {e}")
    
    return list(all_symbols)

def filter_and_save_stocks(symbols):
    """ç­›é€‰å¹¶ä¿å­˜åˆ°æ•°æ®åº“"""
    
    engine = create_engine(settings.database_url)
    filtered = []
    
    logger.info(f"å¼€å§‹ç­›é€‰ {len(symbols)} åªè‚¡ç¥¨...")
    
    for i, symbol in enumerate(symbols, 1):
        try:
            # è·å–è‚¡ç¥¨ä¿¡æ¯
            ticker = yf.Ticker(symbol)
            info = ticker.info
            
            market_cap = info.get('marketCap', 0)
            price = info.get('currentPrice', 0)
            sector = info.get('sector', 'Unknown')
            
            # ç­›é€‰æ¡ä»¶ï¼š5äº¿-100äº¿å¸‚å€¼
            if 500_000_000 <= market_cap <= 10_000_000_000:
                if 5 <= price <= 150:
                    filtered.append({
                        'code': symbol,
                        'name': info.get('shortName', symbol),
                        'market': 'US',
                        'sector': sector,
                        'industry': info.get('industry', 'Unknown'),
                        'market_cap': market_cap / 1_000_000,  # è½¬ä¸ºç™¾ä¸‡ç¾å…ƒ
                    })
            
            # è¿›åº¦æ˜¾ç¤º
            if i % 100 == 0:
                logger.info(f"è¿›åº¦: {i}/{len(symbols)}, å·²ç­›é€‰: {len(filtered)}")
        
        except Exception as e:
            logger.debug(f"è·³è¿‡ {symbol}: {e}")
    
    logger.info(f"âœ… ç­›é€‰å®Œæˆ: {len(filtered)} åªè‚¡ç¥¨ç¬¦åˆæ¡ä»¶")
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    if filtered:
        df = pd.DataFrame(filtered)
        df.to_sql('stocks', engine, if_exists='append', index=False)
        logger.info("âœ… å·²ä¿å­˜åˆ°æ•°æ®åº“")
    
    # åŒæ—¶ä¿å­˜åˆ°JSONï¼ˆå¤‡ä»½ï¼‰
    import json
    with open('data/us_stock_universe.json', 'w') as f:
        json.dump(filtered, f, indent=2)
    logger.info("âœ… å·²ä¿å­˜åˆ° data/us_stock_universe.json")
    
    return filtered

if __name__ == "__main__":
    logger.info("=" * 60)
    logger.info("å¼€å§‹æ„å»ºç¾è‚¡è‚¡ç¥¨æ± ")
    logger.info("=" * 60)
    
    # 1. ä»Wikipediaè·å–
    symbols = get_stocks_from_wikipedia()
    logger.info(f"æ€»è®¡è·å–: {len(symbols)} åªè‚¡ç¥¨ï¼ˆå»é‡å‰ï¼‰")
    
    # 2. ç­›é€‰å¹¶ä¿å­˜
    filtered = filter_and_save_stocks(symbols)
    
    logger.info("=" * 60)
    logger.info(f"âœ… è‚¡ç¥¨æ± æ„å»ºå®Œæˆï¼ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨: {len(filtered)} åª")
    logger.info("=" * 60)
```

### æ­¥éª¤2ï¼šå®šæœŸæ›´æ–°ï¼ˆæ¯æœˆ1æ¬¡ï¼‰

```python
# è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼Œæ¯æœˆæ›´æ–°ä¸€æ¬¡è‚¡ç¥¨æ± 
# å› ä¸ºæŒ‡æ•°æˆåˆ†è‚¡å˜åŒ–ä¸é¢‘ç¹

from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

# æ¯æœˆ1å·å‡Œæ™¨æ›´æ–°
scheduler.add_job(
    update_stock_universe,
    'cron',
    day=1,
    hour=0,
    minute=0,
)
```

---

## ğŸ“Š é¢„æœŸç»“æœ

### è‚¡ç¥¨æ± ç»Ÿè®¡

```
æ¥æºåˆ†å¸ƒï¼š
- Russell 2000: ~2000åª
- SP600: ~600åª
- NASDAQ 100: ~100åª

å»é‡åæ€»æ•°: ~2500åª

ç­›é€‰åï¼ˆ5äº¿-100äº¿å¸‚å€¼ï¼‰: ~600-800åª

æ¿å—åˆ†å¸ƒï¼š
- Healthcare/Biotechnology: ~200åª
- Technology: ~150åª
- Consumer: ~100åª
- Energy: ~80åª
- Industrials: ~70åª
- Financials: ~60åª
- å…¶ä»–: ~140åª
```

---

## âš¡ å¿«é€Ÿæµ‹è¯•

### æµ‹è¯•è„šæœ¬

```python
# test_stock_universe.py

import json

# 1. åŠ è½½è‚¡ç¥¨æ± 
with open('data/us_stock_universe.json') as f:
    stocks = json.load(f)

print(f"âœ… è‚¡ç¥¨æ± æ€»æ•°: {len(stocks)}")

# 2. æŒ‰æ¿å—ç»Ÿè®¡
from collections import Counter
sectors = Counter(s['sector'] for s in stocks)

print("\nğŸ“Š æ¿å—åˆ†å¸ƒ:")
for sector, count in sectors.most_common():
    print(f"  {sector}: {count} åª")

# 3. æŒ‰å¸‚å€¼ç»Ÿè®¡
market_caps = [s['market_cap'] for s in stocks]
print(f"\nğŸ’° å¸‚å€¼èŒƒå›´:")
print(f"  æœ€å°: ${min(market_caps)/1000:.1f}M")
print(f"  æœ€å¤§: ${max(market_caps)/1000:.1f}M")
print(f"  ä¸­ä½æ•°: ${sorted(market_caps)[len(market_caps)//2]/1000:.1f}M")

# 4. éšæœºæŠ½æ ·
import random
samples = random.sample(stocks, 10)
print("\nğŸ² éšæœºæ ·æœ¬:")
for s in samples:
    print(f"  {s['code']:6s} {s['name']:30s} {s['sector']:20s} ${s['market_cap']/1000:.0f}M")
```

---

## ğŸ’¡ ç»´æŠ¤å»ºè®®

### æ›´æ–°é¢‘ç‡

```
åˆå§‹æ„å»ºï¼šè¿è¡Œä¸€æ¬¡ï¼ˆçº¦30åˆ†é’Ÿï¼‰
å®šæœŸæ›´æ–°ï¼šæ¯æœˆ1æ¬¡ï¼ˆæŒ‡æ•°è°ƒæ•´ï¼‰
ä¸´æ—¶æ·»åŠ ï¼šæ‰‹åŠ¨åŠ å…¥çƒ­é—¨è‚¡ç¥¨
```

### æ•°æ®è´¨é‡ä¿è¯

```python
# æ¯æ¬¡æ›´æ–°åæ£€æŸ¥
def validate_stock_universe():
    """éªŒè¯è‚¡ç¥¨æ± è´¨é‡"""
    
    # 1. æ£€æŸ¥æ•°é‡
    assert 600 <= len(stocks) <= 1000, "è‚¡ç¥¨æ•°é‡å¼‚å¸¸"
    
    # 2. æ£€æŸ¥å¿…å¡«å­—æ®µ
    for stock in stocks:
        assert stock.get('symbol')
        assert stock.get('sector')
        assert stock.get('market_cap')
    
    # 3. æ£€æŸ¥å¸‚å€¼èŒƒå›´
    for stock in stocks:
        cap = stock['market_cap']
        assert 500_000_000 <= cap <= 10_000_000_000
    
    print("âœ… è‚¡ç¥¨æ± éªŒè¯é€šè¿‡")
```

---

## ğŸ¯ æ€»ç»“

### æ¨èæ–¹æ¡ˆï¼šWikipedia + ç­›é€‰

**ä¼˜åŠ¿**ï¼š
- âœ… å®Œå…¨è‡ªåŠ¨åŒ–
- âœ… 10-30åˆ†é’Ÿå®Œæˆ
- âœ… è·å¾—600-800åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
- âœ… æ— éœ€æ‰‹åŠ¨ç»´æŠ¤

**æ­¥éª¤**ï¼š
1. è¿è¡Œ `scripts/init_stock_universe.py`
2. ç­‰å¾…30åˆ†é’Ÿï¼ˆè‡ªåŠ¨è·å–å’Œç­›é€‰ï¼‰
3. æ£€æŸ¥ `data/us_stock_universe.json`
4. å®Œæˆï¼

**ä¸‹ä¸€æ­¥**ï¼š
- å®ç°æ¯æ—¥æ‰«æç³»ç»Ÿ
- ä½¿ç”¨è¿™ä¸ªè‚¡ç¥¨æ± è¿›è¡Œæ‰«æ
- æ¯æœˆæ›´æ–°ä¸€æ¬¡è‚¡ç¥¨æ± 

---

**ä¸éœ€è¦æ‰‹åŠ¨ç»´æŠ¤600-800åªè‚¡ç¥¨ï¼å…¨è‡ªåŠ¨ï¼** ğŸš€

