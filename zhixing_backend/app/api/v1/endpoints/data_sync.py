"""
æ•°æ®åŒæ­¥APIæ¥å£
æä¾›æ‰‹åŠ¨è§¦å‘æ•°æ®åŒæ­¥å’ŒæŸ¥çœ‹åŒæ­¥çŠ¶æ€çš„åŠŸèƒ½
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks, Query
from typing import Dict, Any, List
from datetime import datetime
from loguru import logger

from ....services.data_sync_service import DataSyncService
from ....core.market_data.yahoo_provider import YahooFinanceProvider
from ....repositories.stock_repository import StockRepository
from ....repositories.kline_repository import KLineRepository

router = APIRouter()

# åˆ›å»ºæœåŠ¡å®ä¾‹
yahoo_provider = YahooFinanceProvider(rate_limit_delay=0.2)
stock_repository = StockRepository()
kline_repository = KLineRepository()
data_sync_service = DataSyncService(yahoo_provider, stock_repository, kline_repository)


@router.post("/sync/trigger")
async def trigger_data_sync(
    background_tasks: BackgroundTasks,
    force_full: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶å…¨é‡åŒæ­¥"),
    run_in_background: bool = Query(True, description="æ˜¯å¦åœ¨åå°è¿è¡Œ")
) -> Dict[str, Any]:
    """
    æ‰‹åŠ¨è§¦å‘æ•°æ®åŒæ­¥
    
    Args:
        force_full: æ˜¯å¦å¼ºåˆ¶å…¨é‡åŒæ­¥ï¼ˆå¦åˆ™å¢é‡åŒæ­¥ï¼‰
        run_in_background: æ˜¯å¦åœ¨åå°è¿è¡Œ
    
    Returns:
        åŒæ­¥ä»»åŠ¡ä¿¡æ¯
    """
    try:
        logger.info(f"ğŸš€ æ‰‹åŠ¨è§¦å‘æ•°æ®åŒæ­¥: force_full={force_full}, background={run_in_background}")
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨åŒæ­¥
        if data_sync_service.is_syncing:
            raise HTTPException(
                status_code=409,
                detail="æ•°æ®åŒæ­¥æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•"
            )
        
        if run_in_background:
            # åå°è¿è¡Œ
            background_tasks.add_task(data_sync_service.sync_all_watchlist_data, force_full)
            
            return {
                "success": True,
                "message": "æ•°æ®åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨",
                "sync_type": "full" if force_full else "incremental",
                "mode": "background",
                "start_time": datetime.now().isoformat(),
                "status": "started"
            }
        else:
            # å‰å°è¿è¡Œï¼ˆç­‰å¾…å®Œæˆï¼‰
            sync_result = await data_sync_service.sync_all_watchlist_data(force_full)
            
            return {
                "success": True,
                "message": "æ•°æ®åŒæ­¥å®Œæˆ",
                "sync_result": sync_result
            }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è§¦å‘æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"è§¦å‘æ•°æ®åŒæ­¥å¤±è´¥: {str(e)}"
        )


@router.get("/sync/status")
async def get_sync_status() -> Dict[str, Any]:
    """è·å–æ•°æ®åŒæ­¥çŠ¶æ€"""
    try:
        status = await data_sync_service.get_sync_status()
        
        # è·å–è‡ªé€‰è‚¡æ•°é‡
        stocks = await stock_repository.get_all_stocks()
        stock_count = len(stocks) if stocks else 0
        
        # è·å–Kçº¿æ•°æ®ç»Ÿè®¡
        kline_stats = await kline_repository.get_data_statistics()
        
        return {
            "success": True,
            "sync_status": { **status, "last_sync_time": data_sync_service.get_last_sync_time() },
            "watchlist_count": stock_count,
            "data_statistics": kline_stats,
            "current_time": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {str(e)}"
        )


@router.post("/sync/cleanup")
async def cleanup_old_data(
    days_to_keep: int = Query(90, description="ä¿ç•™æ•°æ®çš„å¤©æ•°", ge=7, le=365)
) -> Dict[str, Any]:
    """æ¸…ç†è¿‡æœŸæ•°æ®"""
    try:
        logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ®ï¼Œä¿ç•™æœ€è¿‘ {days_to_keep} å¤©")
        
        deleted_count = await data_sync_service.cleanup_old_data(days_to_keep)
        
        return {
            "success": True,
            "message": f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} æ¡è¿‡æœŸæ•°æ®",
            "deleted_count": deleted_count,
            "days_kept": days_to_keep,
            "cleanup_time": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {str(e)}"
        )


## åˆ é™¤æµ‹è¯•æ¥å£ï¼Œä¿æŒæ•´æ´


## åˆ é™¤è®¡åˆ’é…ç½®æ¥å£ï¼Œå¾…æœªæ¥å¼•å…¥è°ƒåº¦å™¨åå†å®ç°

@router.get("/sync/last-result")
async def get_last_sync_result() -> Dict[str, Any]:
    try:
        return {"success": True, "data": data_sync_service.get_last_result()}
    except Exception as e:
        logger.error(f"è·å–æœ€è¿‘ä¸€æ¬¡åŒæ­¥ç»“æœå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/sync/retry-failed")
async def retry_failed_symbols(background_tasks: BackgroundTasks, force_full: bool = Query(False)) -> Dict[str, Any]:
    try:
        last = data_sync_service.get_last_result()
        failed_symbols: List[str] = []
        details = (last or {}).get("details", {})
        for sym, info in details.items():
            if not info.get("success"):
                failed_symbols.append(sym)
        if not failed_symbols:
            return {"success": True, "message": "æ— å¤±è´¥è‚¡ç¥¨å¯é‡è¯•", "data": {"failed_symbols": []}}

        # åå°é‡è¯•
        background_tasks.add_task(data_sync_service.sync_specific_symbols, failed_symbols, force_full)
        return {"success": True, "message": "å·²å‘èµ·å¤±è´¥é‡è¯•", "data": {"failed_symbols": failed_symbols}}
    except Exception as e:
        logger.error(f"é‡è¯•å¤±è´¥è‚¡ç¥¨è§¦å‘å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é‡è¯•è§¦å‘å¤±è´¥: {str(e)}")
