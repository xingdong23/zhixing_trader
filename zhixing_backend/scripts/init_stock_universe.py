"""
åˆå§‹åŒ–ç¾Žè‚¡è‚¡ç¥¨æ± 
ä»ŽWikipediaè‡ªåŠ¨èŽ·å–Russell 2000ã€SP600ã€NASDAQ 100ç­‰æŒ‡æ•°æˆåˆ†è‚¡
è‡ªåŠ¨ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼ˆå¸‚å€¼5äº¿-100äº¿ç¾Žå…ƒï¼‰
"""
import sys
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import pandas as pd
import yfinance as yf
from loguru import logger
from sqlalchemy import create_engine, text
from app.config import settings


def get_stocks_from_seed_file():
    """ä»Žç§å­æ–‡ä»¶èŽ·å–è‚¡ç¥¨ä»£ç """
    
    seed_file = project_root / 'data' / 'us_stock_symbols.txt'
    
    if not seed_file.exists():
        logger.error(f"ç§å­æ–‡ä»¶ä¸å­˜åœ¨: {seed_file}")
        return []
    
    all_symbols = set()
    
    logger.info(f"ä»Žç§å­æ–‡ä»¶è¯»å–: {seed_file}")
    
    with open(seed_file, 'r') as f:
        for line in f:
            line = line.strip()
            # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if not line or line.startswith('#'):
                continue
            # åˆ†å‰²é€—å·åˆ†éš”çš„è‚¡ç¥¨ä»£ç 
            symbols = [s.strip().upper() for s in line.split(',') if s.strip()]
            all_symbols.update(symbols)
    
    logger.info(f"âœ… ä»Žç§å­æ–‡ä»¶èŽ·å–: {len(all_symbols)} åªè‚¡ç¥¨")
    return list(all_symbols)


def get_stocks_from_wikipedia():
    """ä»ŽWikipediaèŽ·å–å¤šä¸ªæŒ‡æ•°çš„è‚¡ç¥¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    
    all_symbols = set()
    
    # æ·»åŠ User-Agenté¿å…è¢«æ‹¦æˆª
    import requests
    from io import StringIO
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # 1. Russell 2000ï¼ˆå°ç›˜è‚¡ï¼Œçº¦2000åªï¼‰
    logger.info("æ­£åœ¨èŽ·å– Russell 2000...")
    try:
        url = "https://en.wikipedia.org/wiki/Russell_2000_Index"
        response = requests.get(url, headers=headers)
        tables = pd.read_html(StringIO(response.text))
        
        # å°è¯•æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—
        for table in tables:
            if 'Ticker' in table.columns:
                symbols = table['Ticker'].dropna().tolist()
                all_symbols.update(symbols)
                logger.info(f"âœ… Russell 2000: {len(symbols)} åª")
                break
            elif 'Symbol' in table.columns:
                symbols = table['Symbol'].dropna().tolist()
                all_symbols.update(symbols)
                logger.info(f"âœ… Russell 2000: {len(symbols)} åª")
                break
    except Exception as e:
        logger.warning(f"âš ï¸ Russell 2000èŽ·å–å¤±è´¥: {e}")
    
    # 2. S&P 600ï¼ˆå°ç›˜è‚¡ï¼Œçº¦600åªï¼‰
    logger.info("æ­£åœ¨èŽ·å– S&P 600...")
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_600_companies"
        response = requests.get(url, headers=headers)
        tables = pd.read_html(StringIO(response.text))
        df = tables[0]
        symbols = df['Symbol'].dropna().tolist()
        all_symbols.update(symbols)
        logger.info(f"âœ… S&P 600: {len(symbols)} åª")
    except Exception as e:
        logger.warning(f"âš ï¸ S&P 600èŽ·å–å¤±è´¥: {e}")
    
    # 3. NASDAQ 100ï¼ˆç§‘æŠ€è‚¡ï¼Œçº¦100åªï¼‰
    logger.info("æ­£åœ¨èŽ·å– NASDAQ 100...")
    try:
        url = "https://en.wikipedia.org/wiki/Nasdaq-100"
        response = requests.get(url, headers=headers)
        tables = pd.read_html(StringIO(response.text))
        # NASDAQ 100é€šå¸¸åœ¨åŽé¢çš„è¡¨æ ¼
        for table in tables:
            if 'Ticker' in table.columns:
                symbols = table['Ticker'].dropna().tolist()
                if len(symbols) > 50:  # ç¡®ä¿æ˜¯å®Œæ•´åˆ—è¡¨
                    all_symbols.update(symbols)
                    logger.info(f"âœ… NASDAQ 100: {len(symbols)} åª")
                    break
    except Exception as e:
        logger.warning(f"âš ï¸ NASDAQ 100èŽ·å–å¤±è´¥: {e}")
    
    logger.info(f"æ€»è®¡èŽ·å–: {len(all_symbols)} åªè‚¡ç¥¨ï¼ˆåŽ»é‡åŽï¼‰")
    return list(all_symbols)


def filter_and_enrich_stocks(symbols, batch_size=50):
    """
    ç­›é€‰å¹¶ä¸°å¯Œè‚¡ç¥¨ä¿¡æ¯
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        batch_size: æ¯æ‰¹å¤„ç†æ•°é‡ï¼ˆç”¨äºŽè¿›åº¦æ˜¾ç¤ºï¼‰
    
    Returns:
        ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨åˆ—è¡¨
    """
    filtered = []
    total = len(symbols)
    
    logger.info(f"å¼€å§‹ç­›é€‰å’ŒèŽ·å–è¯¦ç»†ä¿¡æ¯...")
    logger.info(f"ç­›é€‰æ¡ä»¶: å¸‚å€¼ $500M-$10B, ä»·æ ¼ $5-$150")
    
    for i, symbol in enumerate(symbols, 1):
        try:
            # æ¸…ç†è‚¡ç¥¨ä»£ç ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            clean_symbol = symbol.strip().upper()
            if not clean_symbol or '.' in clean_symbol:
                continue
            
            # èŽ·å–è‚¡ç¥¨ä¿¡æ¯
            ticker = yf.Ticker(clean_symbol)
            info = ticker.info
            
            # æå–å…³é”®ä¿¡æ¯
            market_cap = info.get('marketCap', 0)
            current_price = info.get('currentPrice', 0) or info.get('regularMarketPrice', 0)
            sector = info.get('sector', 'Unknown')
            
            # å¦‚æžœæ²¡æœ‰å¸‚å€¼ï¼Œå°è¯•ä»Žå…¶ä»–å­—æ®µèŽ·å–
            if market_cap == 0:
                market_cap = info.get('enterpriseValue', 0)
            
            # ç­›é€‰æ¡ä»¶
            if market_cap > 0 and current_price > 0:
                # å¸‚å€¼ï¼š5äº¿-100äº¿ç¾Žå…ƒ
                if 500_000_000 <= market_cap <= 10_000_000_000:
                    # ä»·æ ¼ï¼š$5-$150
                    if 5 <= current_price <= 150:
                        filtered.append({
                            'code': clean_symbol,
                            'name': info.get('shortName', clean_symbol)[:200],  # é™åˆ¶é•¿åº¦
                            'market': 'US',
                            'sector': sector[:50] if sector else 'Unknown',
                            'industry': (info.get('industry', 'Unknown') or 'Unknown')[:100],
                            'market_cap': round(market_cap / 1_000_000, 2),  # è½¬ä¸ºç™¾ä¸‡ç¾Žå…ƒ
                            'current_price': round(current_price, 2),
                        })
            
            # è¿›åº¦æ˜¾ç¤º
            if i % batch_size == 0:
                logger.info(f"è¿›åº¦: {i}/{total} ({i*100//total}%), å·²ç­›é€‰: {len(filtered)} åª")
            
            # é™æµï¼ˆé¿å…è¢«å°ï¼‰
            if i % 10 == 0:
                time.sleep(0.5)
        
        except Exception as e:
            logger.debug(f"è·³è¿‡ {symbol}: {str(e)[:50]}")
            continue
    
    logger.info(f"âœ… ç­›é€‰å®Œæˆ: {len(filtered)}/{total} åªè‚¡ç¥¨ç¬¦åˆæ¡ä»¶")
    return filtered


def save_to_database(stocks):
    """ä¿å­˜åˆ°æ•°æ®åº“"""
    
    if not stocks:
        logger.warning("æ²¡æœ‰è‚¡ç¥¨éœ€è¦ä¿å­˜")
        return
    
    try:
        engine = create_engine(settings.database_url)
        
        with engine.connect() as conn:
            # æ¸…ç©ºçŽ°æœ‰æ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æžœæƒ³å¢žé‡æ›´æ–°åˆ™æ³¨é‡ŠæŽ‰ï¼‰
            # conn.execute(text("DELETE FROM stocks WHERE market = 'US'"))
            # logger.info("å·²æ¸…ç©ºçŽ°æœ‰ç¾Žè‚¡æ•°æ®")
            
            # æ‰¹é‡æ’å…¥
            df = pd.DataFrame(stocks)
            
            # ä½¿ç”¨ to_sql çš„ replace æˆ– append æ¨¡å¼
            df.to_sql(
                'stocks', 
                engine, 
                if_exists='append',  # æˆ– 'replace'
                index=False,
                method='multi',
                chunksize=100
            )
            
            conn.commit()
        
        logger.info(f"âœ… å·²ä¿å­˜ {len(stocks)} åªè‚¡ç¥¨åˆ°æ•°æ®åº“")
    
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        raise


def save_to_json(stocks, filepath='data/us_stock_universe.json'):
    """ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼ˆå¤‡ä»½ï¼‰"""
    
    import json
    from pathlib import Path
    
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(stocks, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… å·²ä¿å­˜åˆ° {filepath}")
    
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ°JSONå¤±è´¥: {e}")


def print_statistics(stocks):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    
    if not stocks:
        return
    
    from collections import Counter
    
    logger.info("=" * 60)
    logger.info("ðŸ“Š è‚¡ç¥¨æ± ç»Ÿè®¡")
    logger.info("=" * 60)
    
    # æ€»æ•°
    logger.info(f"æ€»æ•°: {len(stocks)} åª")
    
    # æ¿å—åˆ†å¸ƒ
    sectors = Counter(s['sector'] for s in stocks)
    logger.info("\næ¿å—åˆ†å¸ƒï¼ˆTop 10ï¼‰:")
    for sector, count in sectors.most_common(10):
        logger.info(f"  {sector:30s}: {count:3d} åª")
    
    # å¸‚å€¼ç»Ÿè®¡
    market_caps = [s['market_cap'] for s in stocks]
    logger.info(f"\nå¸‚å€¼èŒƒå›´:")
    logger.info(f"  æœ€å°: ${min(market_caps):.1f}M")
    logger.info(f"  æœ€å¤§: ${max(market_caps):.1f}M")
    logger.info(f"  å¹³å‡: ${sum(market_caps)/len(market_caps):.1f}M")
    logger.info(f"  ä¸­ä½æ•°: ${sorted(market_caps)[len(market_caps)//2]:.1f}M")
    
    # ä»·æ ¼ç»Ÿè®¡
    prices = [s['current_price'] for s in stocks]
    logger.info(f"\nä»·æ ¼èŒƒå›´:")
    logger.info(f"  æœ€ä½Ž: ${min(prices):.2f}")
    logger.info(f"  æœ€é«˜: ${max(prices):.2f}")
    logger.info(f"  å¹³å‡: ${sum(prices)/len(prices):.2f}")
    
    # éšæœºæ ·æœ¬
    import random
    samples = random.sample(stocks, min(5, len(stocks)))
    logger.info("\néšæœºæ ·æœ¬:")
    for s in samples:
        logger.info(f"  {s['code']:6s} | {s['name']:30s} | {s['sector']:20s} | ${s['market_cap']:.0f}M")
    
    logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    
    logger.info("=" * 60)
    logger.info("ðŸš€ å¼€å§‹æž„å»ºç¾Žè‚¡è‚¡ç¥¨æ± ")
    logger.info("=" * 60)
    
    start_time = time.time()
    
    try:
        # 1. èŽ·å–è‚¡ç¥¨ä»£ç 
        logger.info("\nã€æ­¥éª¤1ã€‘èŽ·å–è‚¡ç¥¨ä»£ç ...")
        
        # å…ˆå°è¯•ä»Žç§å­æ–‡ä»¶èŽ·å–
        symbols = get_stocks_from_seed_file()
        
        # å¦‚æžœç§å­æ–‡ä»¶ä¸ºç©ºï¼Œå°è¯•Wikipedia
        if not symbols:
            logger.info("ç§å­æ–‡ä»¶ä¸ºç©ºï¼Œå°è¯•ä»ŽWikipediaèŽ·å–...")
            symbols = get_stocks_from_wikipedia()
        
        if not symbols:
            logger.error("âŒ æœªèƒ½èŽ·å–ä»»ä½•è‚¡ç¥¨ä»£ç ")
            logger.info("ðŸ’¡ æç¤ºï¼šå¯ä»¥æ‰‹åŠ¨ç¼–è¾‘ data/us_stock_symbols.txt æ·»åŠ è‚¡ç¥¨ä»£ç ")
            return
        
        # 2. ç­›é€‰å¹¶èŽ·å–è¯¦ç»†ä¿¡æ¯
        logger.info("\nã€æ­¥éª¤2ã€‘ç­›é€‰å¹¶èŽ·å–è¯¦ç»†ä¿¡æ¯...")
        filtered_stocks = filter_and_enrich_stocks(symbols)
        
        if not filtered_stocks:
            logger.error("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return
        
        # 3. ä¿å­˜åˆ°æ•°æ®åº“
        logger.info("\nã€æ­¥éª¤3ã€‘ä¿å­˜åˆ°æ•°æ®åº“...")
        save_to_database(filtered_stocks)
        
        # 4. ä¿å­˜åˆ°JSONï¼ˆå¤‡ä»½ï¼‰
        logger.info("\nã€æ­¥éª¤4ã€‘ä¿å­˜åˆ°JSONæ–‡ä»¶...")
        save_to_json(filtered_stocks)
        
        # 5. æ‰“å°ç»Ÿè®¡
        logger.info("\nã€æ­¥éª¤5ã€‘ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        print_statistics(filtered_stocks)
        
        # å®Œæˆ
        elapsed = time.time() - start_time
        logger.info("=" * 60)
        logger.info(f"âœ… è‚¡ç¥¨æ± æž„å»ºå®Œæˆï¼")
        logger.info(f"   ç¬¦åˆæ¡ä»¶: {len(filtered_stocks)} åª")
        logger.info(f"   è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
        logger.info("=" * 60)
    
    except Exception as e:
        logger.error(f"âŒ æž„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

